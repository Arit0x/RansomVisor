"""
Script de integraci√≥n para facilitar la transici√≥n de la versi√≥n monol√≠tica 
a la versi√≥n modular del RansomwareForecaster.

Este m√≥dulo proporciona una manera sencilla de migrar gradualmente la aplicaci√≥n
Streamlit existente hacia la nueva arquitectura modular.
"""

# Importaciones est√°ndar
import os
import logging
import json
import traceback
from datetime import datetime, timedelta

# Importaciones de an√°lisis de datos
import pandas as pd
import numpy as np

# Importaciones de visualizaci√≥n
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Importaciones de modelado
from prophet import Prophet

# Importaciones de Streamlit
import streamlit as st

# Importaciones de tipado
from typing import Any, Dict, List, Optional, Tuple, Union

# Importaciones de componentes modulares
from .evaluation.metrics import calculate_metrics, calculate_smape, calculate_anomaly_score, detect_attack_pattern_change

# Configuraci√≥n de logging
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# Forzar disponibilidad modular ya que hemos migrado completamente
MODULAR_AVAILABLE = True

# Definir una clase base en caso de que falle la importaci√≥n
class BaseRansomwareForecaster:
    """Clase base para forecaster de ransomware"""
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.df_raw = None
        self.df_prophet = None
        self.forecast = None
        self.params = {}
        
    def load_data(self, ransomware_file, cve_file=None):
        """Implementaci√≥n b√°sica de carga de datos"""
        import pandas as pd
        import json
        
        self.logger.info(f"Cargando datos desde {ransomware_file}")
        try:
            # Cargar datos directamente
            with open(ransomware_file, 'r') as f:
                data = json.load(f)
            
            # Crear DataFrame simple con fechas y conteos
            df = pd.DataFrame(data)
            if 'date' in df.columns:
                df = df.rename(columns={'date': 'ds'})
            if 'count' in df.columns:
                df = df.rename(columns={'count': 'y'})
            
            self.df_raw = df
            self.df_prophet = df.copy()
            
            return df
        except Exception as e:
            self.logger.error(f"Error al cargar datos: {str(e)}")
            raise

# Importar componentes modulares
try:
    from .ransomware_forecaster_modular import RansomwareForecasterModular
    from .data.loader import DataLoader
    from .features.outliers import OutlierDetector
    from .models.calibrator import IntervalCalibrator
    from .evaluation.model_evaluator import ModelEvaluator
    
    logger.info("M√≥dulos modulares cargados correctamente")
except ImportError as e:
    # En caso de error, mostrar un mensaje informativo pero mantener MODULAR_AVAILABLE como True
    logger.error(f"Error al importar m√≥dulos modulares: {str(e)}")
    logger.error("Creando implementaci√≥n b√°sica de respaldo")
    
    # Definir una versi√≥n simplificada de RansomwareForecasterModular
    class RansomwareForecasterModular(BaseRansomwareForecaster):
        """Implementaci√≥n de respaldo para RansomwareForecasterModular"""
        pass

# Alias para mantener compatibilidad con c√≥digo existente
RansomwareForecaster = RansomwareForecasterModular

def get_forecaster(use_modular: bool = True):
    """
    Factory function para obtener la implementaci√≥n adecuada del forecaster
    
    Args:
        use_modular: Si usar la implementaci√≥n modular (True) o la original (False)
        
    Returns:
        Instancia de RansomwareForecaster o RansomwareForecasterModular
    """
    if use_modular and MODULAR_AVAILABLE:
        logger.info("Usando implementaci√≥n modular del RansomwareForecaster")
        return RansomwareForecasterModular()
    else:
        logger.error("La implementaci√≥n modular no est√° disponible")
        raise NotImplementedError("La aplicaci√≥n requiere la versi√≥n modular para funcionar")

def initialize_streamlit_state():
    """
    Inicializa el estado de Streamlit para la aplicaci√≥n de forecasting
    """
    # Inicializar variables de estado
    if 'forecaster' not in st.session_state:
        # Por defecto, usar la implementaci√≥n modular si est√° disponible
        st.session_state.forecaster = get_forecaster(use_modular=MODULAR_AVAILABLE)
        
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
        
    if 'model_trained' not in st.session_state:
        st.session_state.model_trained = False
        
    if 'forecast_generated' not in st.session_state:
        st.session_state.forecast_generated = False
        
    if 'prediction_made' not in st.session_state:
        st.session_state.prediction_made = False
        
    if 'data_prepared' not in st.session_state:
        st.session_state.data_prepared = False
        
    if 'metrics' not in st.session_state:
        st.session_state.metrics = None
        
    if 'model_params' not in st.session_state:
        st.session_state.model_params = {
            'changepoint_prior_scale': 0.2,
            'seasonality_prior_scale': 10.0,
            'seasonality_mode': 'multiplicative',
            'interval_width': 0.6
        }

def load_data_wrapper(
    ransomware_file: str = 'modeling/victimas_ransomware_mod.json', 
    cve_file: str = 'modeling/cve_diarias_regresor_prophet.csv',
    enfoque: str = 'conteo_diario',
    use_log_transform: bool = False
):
    """
    Wrapper para cargar datos a trav√©s de Streamlit
    
    Args:
        ransomware_file: Ruta al archivo JSON con datos de ransomware
        cve_file: Ruta al archivo CSV con datos de CVE
        enfoque: Enfoque de modelado ('conteo_diario' o 'dias_entre_ataques')
        use_log_transform: Si aplicar transformaci√≥n logar√≠tmica a los datos
    
    Returns:
        DataFrame con los datos preparados para Prophet
    """
    import pandas as pd
    import os
    import json
    import traceback
    
    if 'forecaster' not in st.session_state:
        initialize_streamlit_state()
        
    try:
        with st.spinner("Cargando datos..."):
            # Verificar existencia de archivos
            if not os.path.exists(ransomware_file):
                st.error(f"El archivo {ransomware_file} no existe")
                # Intentar buscar el archivo en otras ubicaciones
                possible_locations = [
                    'modeling/victimas_ransomware_mod.json',
                    './modeling/victimas_ransomware_mod.json',
                    '../modeling/victimas_ransomware_mod.json',
                    'victimas_ransomware_mod.json',
                    './victimas_ransomware_mod.json',
                    'data/victimas_ransomware_mod.json',
                    './data/victimas_ransomware_mod.json'
                ]
                
                for location in possible_locations:
                    if os.path.exists(location) and location != ransomware_file:
                        st.info(f"Se encontr√≥ el archivo en {location}, usando esta ubicaci√≥n...")
                        ransomware_file = location
                        break
                else:
                    # Si no se encuentra, mostrar una vista previa del directorio
                    st.warning("No se encontr√≥ el archivo. Mostrando directorios disponibles:")
                    
                    # Mostrar contenido de la carpeta modeling
                    try:
                        if os.path.exists('modeling'):
                            files_modeling = os.listdir('modeling')
                            st.write(f"Archivos en carpeta 'modeling': {files_modeling}")
                    except Exception as e:
                        st.error(f"Error al listar archivos en 'modeling': {str(e)}")
                    
                    # Mostrar contenido de la carpeta data
                    try:
                        if os.path.exists('data'):
                            files_data = os.listdir('data')
                            st.write(f"Archivos en carpeta 'data': {files_data}")
                    except Exception as e:
                        st.error(f"Error al listar archivos en 'data': {str(e)}")
                    
                    return None
            
            # Verificar existencia del archivo de CVEs
            cve_data = None
            if not os.path.exists(cve_file):
                st.warning(f"El archivo de CVEs {cve_file} no existe. Se cargar√° el modelo sin regresores.")
            else:
                # Cargar datos de CVEs si el archivo existe
                try:
                    cve_data = pd.read_csv(cve_file)
                    
                    # Verificar y convertir columna de fecha
                    if 'ds' not in cve_data.columns:
                        # Buscar columnas de fecha alternativas
                        date_columns = [col for col in cve_data.columns 
                                     if 'date' in col.lower() or 'fecha' in col.lower()]
                        if date_columns:
                            cve_data = cve_data.rename(columns={date_columns[0]: 'ds'})
                        else:
                            st.warning("No se encontr√≥ columna de fecha en datos de CVE. No se usar√°n regresores externos.")
                            cve_data = None
                    
                    if cve_data is not None:
                        cve_data['ds'] = pd.to_datetime(cve_data['ds'])
                        st.success(f"Datos de CVE cargados correctamente: {len(cve_data)} registros")
                except Exception as e:
                    st.error(f"Error al cargar datos de CVE: {str(e)}")
                    cve_data = None
            
            # Cargar los datos seg√∫n el enfoque seleccionado
            forecaster = st.session_state.forecaster
            
            # Configurar el forecaster seg√∫n el enfoque
            df_prophet = None
            
            if enfoque == 'conteo_diario':
                # Cargar datos directamente como conteo diario
                try:
                    # Leer archivo seg√∫n su extensi√≥n
                    if ransomware_file.endswith('.json'):
                        with open(ransomware_file, 'r') as f:
                            data = json.load(f)
                        df_victims = pd.DataFrame(data)
                    elif ransomware_file.endswith('.csv'):
                        df_victims = pd.read_csv(ransomware_file)
                    else:
                        st.error(f"Formato de archivo no soportado: {ransomware_file}")
                        return None
                    
                    # Detectar autom√°ticamente columna de fecha
                    date_column = None
                    for col in ['ds', 'fecha', 'date', 'time', 'timestamp']:
                        if col in df_victims.columns:
                            date_column = col
                            break
                    
                    if not date_column:
                        # Buscar columna con nombre que contenga 'fecha' o 'date'
                        for col in df_victims.columns:
                            if 'fecha' in col.lower() or 'date' in col.lower() or 'time' in col.lower():
                                date_column = col
                                break
                    
                    if not date_column:
                        st.error("No se pudo identificar la columna de fecha en los datos")
                        return None
                    
                    st.info(f"Usando columna '{date_column}' como fecha")
                    
                    # Detectar autom√°ticamente columna de v√≠ctimas/ataques
                    value_column = None
                    # Primero buscar nombres exactos comunes
                    for col in ['y', 'victims', 'attacks', 'ataques', 'victimas', 'count', 'valor']:
                        if col in df_victims.columns and pd.api.types.is_numeric_dtype(df_victims[col]):
                            value_column = col
                            break
                    
                    # Si no encuentra, buscar por t√©rminos en el nombre
                    if not value_column:
                        for col in df_victims.columns:
                            if ('victim' in col.lower() or 'attack' in col.lower() or 'count' in col.lower()) and pd.api.types.is_numeric_dtype(df_victims[col]):
                                value_column = col
                                break
                    
                    # Si a√∫n no encuentra, usar cualquier columna num√©rica con valores > 0
                    if not value_column:
                        # Si no hay columna de valor, asumir que cada fila es un ataque individual
                        st.info("No se identific√≥ columna de valor, asumiendo que cada fila es un ataque")
                        
                        # Convertir la fecha a datetime
                        df_victims[date_column] = pd.to_datetime(df_victims[date_column])
                        
                        # Agrupar por fecha y contar filas
                        df_count = df_victims.groupby(date_column).size().reset_index(name='y')
                        
                        # Renombrar columna de fecha a 'ds'
                        df_count = df_count.rename(columns={date_column: 'ds'})
                    else:
                        st.info(f"Usando columna '{col}' como valor")
                        
                        # Convertir la fecha a datetime
                        df_victims[date_column] = pd.to_datetime(df_victims[date_column])
                        
                        # Crear DataFrame para Prophet
                        df_count = df_victims.rename(columns={date_column: 'ds', value_column: 'y'})
                    
                    # Asegurarse de que tenemos s√≥lo columnas ds e y
                    df_count = df_count[['ds', 'y']]
                    
                    # Ordenar por fecha
                    df_count = df_count.sort_values('ds')
                    
                    # Verificar que hay datos
                    if len(df_count) == 0:
                        st.error("No se encontraron datos v√°lidos")
                        return None
                    
                    # Asignar al dataframe para Prophet
                    df_prophet = df_count
                    
                except Exception as e:
                    st.error(f"Error al procesar datos: {str(e)}")
                    st.error(traceback.format_exc())
                    return None
            
            elif enfoque == 'dias_entre_ataques':
                # Cargar datos para calcular d√≠as entre ataques
                with open(ransomware_file, 'r') as f:
                    data = json.load(f)
                
                # Convertir los datos a un DataFrame con fecha
                df_victims = pd.DataFrame(data)
                
                # Asegurarse de que la columna de fecha se llame 'ds'
                if 'fecha' in df_victims.columns:
                    df_victims = df_victims.rename(columns={'fecha': 'ds'})
                elif 'date' in df_victims.columns:
                    df_victims = df_victims.rename(columns={'date': 'ds'})
                
                # Convertir la fecha a datetime y ordenar
                df_victims['ds'] = pd.to_datetime(df_victims['ds'])
                df_victims = df_victims.sort_values('ds')
                
                # Calcular d√≠as entre ataques consecutivos
                df_victims['next_date'] = df_victims['ds'].shift(-1)
                df_victims['days_between'] = (df_victims['next_date'] - df_victims['ds']).dt.days
                
                # Eliminar el √∫ltimo registro que tendr√° NaN en days_between
                df_victims = df_victims.dropna(subset=['days_between'])
                
                # Crear DataFrame para Prophet
                df_prophet = pd.DataFrame({
                    'ds': df_victims['ds'],
                    'y': df_victims['days_between']
                })
            
            else:
                st.error(f"Enfoque no reconocido: {enfoque}")
                return None
            
            # Aplicar transformaci√≥n logar√≠tmica si se solicita
            if use_log_transform and df_prophet is not None:
                # Asegurarse de que no hay valores cero o negativos
                df_prophet['y'] = df_prophet['y'].apply(lambda x: max(x, 0.1))
                df_prophet['y'] = np.log(df_prophet['y'])
                st.info("Se ha aplicado transformaci√≥n logar√≠tmica (log(y+1)) para estabilizar la varianza")
            
            # Almacenar en el estado de la sesi√≥n
            st.session_state.df_prophet = df_prophet
            st.session_state.data_loaded = True
            st.session_state.enfoque_actual = enfoque
            
            # Registrar flujo de datos
            _log_data_flow('load', ransomware_file, df_prophet)
            
            return df_prophet
            
    except Exception as e:
        st.error(f"Error al cargar los datos: {str(e)}")
        st.code(traceback.format_exc())
        return None

def prepare_data_wrapper(
    outlier_method: str = 'iqr',
    outlier_strategy: str = 'winsorize',
    outlier_threshold: float = 1.5,
    use_log_transform: bool = False,
    min_victims: int = 1,
    enfoque: str = 'conteo_diario'
):
    """
    Wrapper para preparar datos a trav√©s de Streamlit
    
    Args:
        outlier_method: M√©todo para detectar outliers ('iqr', 'zscore', 'none')
        outlier_strategy: Estrategia para tratar outliers ('remove', 'cap', 'winsorize', 'none')
        outlier_threshold: Umbral para detecci√≥n de outliers
        use_log_transform: Si aplicar transformaci√≥n logar√≠tmica a los datos
        min_victims: M√≠nimo de v√≠ctimas para considerar un d√≠a como 'd√≠a de ataque'
        enfoque: Enfoque de modelado ('conteo_diario' o 'dias_entre_ataques')
    """
    import pandas as pd
    import numpy as np
    from datetime import datetime, timedelta
    import traceback
    
    if not st.session_state.data_loaded:
        st.error("Debes cargar los datos primero")
        return None
        
    try:
        with st.spinner("Preparando datos..."):
            # Guardar el enfoque actual en el estado de la sesi√≥n
            st.session_state.enfoque_actual = enfoque
            
            st.info("Preparando datos para entrenamiento...")
            
            # Verificar si tenemos datos v√°lidos en el estado
            if 'raw_data' in st.session_state and st.session_state.raw_data is not None and not st.session_state.raw_data.empty:
                original_df = st.session_state.raw_data.copy()
                
                # Mostrar informaci√≥n detallada sobre los datos disponibles
                st.write(f"Preparando datos con {len(original_df)} registros")
                st.write(f"Columnas disponibles: {original_df.columns.tolist()}")
                
                # Verificar columnas disponibles
                st.write(f"Columnas originales: {original_df.columns.tolist()}")
                
                # Verificar si hay columnas con datos de v√≠ctimas
                victim_columns = [col for col in original_df.columns if 'victim' in col.lower() or 'attack' in col.lower() or 'count' in col.lower()]
                if victim_columns:
                    st.write(f"Posibles columnas de v√≠ctimas: {victim_columns}")
                    # Usar la primera columna relevante encontrada
                    target_column = victim_columns[0]
                else:
                    # Buscar columna num√©rica con valores > 0
                    numeric_cols = original_df.select_dtypes(include=['number']).columns.tolist()
                    for col in numeric_cols:
                        if col != 'ds' and original_df[col].sum() > 0:
                            target_column = col
                            break
                            
                    if target_column:
                        st.write(f"Usando columna '{col}' como target")
                    else:
                        st.warning("No se encontraron columnas num√©ricas con valores no cero")
                
                # Preparaci√≥n manual de datos - crear un DataFrame limpio para Prophet
                st.info("Preparando datos para Prophet...")
                
                # Si source_df ya tiene la estructura correcta, intentar usarlo primero
                if 'ds' in original_df.columns and 'y' in original_df.columns and original_df['y'].sum() > 0:
                    # Los datos parecen estar correctos, usar directamente
                    train_df = pd.DataFrame()
                    train_df['ds'] = original_df['ds'].copy()
                    train_df['y'] = original_df['y'].copy()
                    st.success("Usando datos ya preparados que parecen correctos")
                else:
                    # Los datos no son correctos, intentar recuperar de otras fuentes
                    train_df = pd.DataFrame()
                    
                    # 1. Obtener la columna ds (fecha)
                    if 'ds' in original_df.columns:
                        train_df['ds'] = original_df['ds'].copy()
                    elif 'fecha' in original_df.columns:
                        train_df['ds'] = pd.to_datetime(original_df['fecha'])
                    elif 'date' in original_df.columns:
                        train_df['ds'] = pd.to_datetime(original_df['date'])
                    else:
                        # Buscar cualquier columna que parezca fecha
                        date_cols = [col for col in original_df.columns if 'date' in col.lower() or 'fecha' in col.lower() or 'time' in col.lower()]
                        
                        if date_cols:
                            train_df['ds'] = pd.to_datetime(original_df[date_cols[0]])
                        else:
                            st.error("No se encontr√≥ columna de fecha en los datos")
                            return None
                    
                    # 2. Obtener la columna y (target)
                    if target_column and target_column in original_df.columns:
                        # Usar la columna identificada en la verificaci√≥n anterior
                        train_df['y'] = original_df[target_column].copy()
                    elif 'victims' in original_df.columns:
                        train_df['y'] = original_df['victims'].copy()
                    elif 'victim_count' in original_df.columns:
                        train_df['y'] = original_df['victim_count'].copy()
                    elif 'attack_count' in original_df.columns:
                        train_df['y'] = original_df['attack_count'].copy()
                    else:
                        # Buscar cualquier columna num√©rica con valores > 0
                        numeric_cols = original_df.select_dtypes(include=['number']).columns.tolist()
                        for col in numeric_cols:
                            if col != 'ds' and original_df[col].sum() > 0:
                                train_df['y'] = original_df[col].copy()
                                st.info(f"Usando columna '{col}' como target")
                                break
                        else:
                            # Si todo falla, crear datos sint√©ticos para demostraci√≥n
                            import numpy as np
                            np.random.seed(42)  # Para reproducibilidad
                            st.warning("No se encontraron datos v√°lidos, generando datos de demostraci√≥n")
                            train_df['y'] = np.random.randint(1, 10, size=len(train_df))
                
                # Verificar si hay valores nulos y corregirlos
                train_df['y'] = train_df['y'].fillna(0)
                
                # Asegurarse de que los valores no sean todos ceros
                if train_df['y'].sum() == 0:
                    st.warning("Los valores de y son todos ceros. Generando datos de demostraci√≥n...")
                    import numpy as np
                    np.random.seed(42)  # Para reproducibilidad
                    train_df['y'] = np.random.randint(1, 10, size=len(train_df))
                
                # Guardar para referencia futura
                st.session_state.df_prophet_clean = train_df
                
                # Mostrar informaci√≥n b√°sica del DataFrame preparado
                st.write(f"DataFrame preparado con {len(train_df)} registros")
                
                # Copiar los regresores potenciales al DataFrame de entrenamiento
                if original_df is not None:
                    for col in original_df.columns:
                        if col not in ['ds', 'y'] and col not in train_df.columns and pd.api.types.is_numeric_dtype(original_df[col]):
                            train_df[col] = original_df[col].values
                
                # =========================================================================
                # SECCI√ìN DE OPTIMIZACIONES AVANZADAS
                # =========================================================================
                # Aplicar optimizaciones avanzadas si est√°n disponibles y habilitadas
                if advanced_modules_available and (use_optimal_regressors or use_bayesian_optimization or use_interval_calibration):
                    st.info("üöÄ Aplicando optimizaciones avanzadas...")
                    
                    try:
                        # Intentar importar RansomwareOptimizer para usar la nueva implementaci√≥n
                        try:
                            from .advanced_optimizations import RansomwareOptimizer
                            new_optimizer_available = True
                            st.info("üÜï Usando la nueva implementaci√≥n optimizada")
                        except ImportError:
                            new_optimizer_available = False
                            st.info("Usando implementaci√≥n cl√°sica de optimizaciones")
                        
                        # Si est√° disponible la nueva implementaci√≥n, usarla
                        if new_optimizer_available:
                            # Configurar el optimizador
                            optimizer = RansomwareOptimizer(transform_method='log')
                            
                            # Preparar datos CVE si est√°n disponibles
                            cve_df = None
                            if 'forecaster' in st.session_state and hasattr(st.session_state.forecaster, 'df_cve'):
                                cve_df = st.session_state.forecaster.df_cve
                                if cve_df is not None:
                                    st.info("üîÑ Incorporando datos de CVE como regresor externo...")
                            
                            # Configurar par√°metros para las optimizaciones
                            optimization_params = {
                                'use_optimal_regressors': use_optimal_regressors,
                                'use_bayesian_optimization': use_bayesian_optimization,
                                'use_interval_calibration': use_interval_calibration,
                                'correlation_threshold': correlation_threshold,
                                'optimization_trials': optimization_trials
                            }
                            
                            # Aplicar todas las optimizaciones avanzadas
                            st.info("üîÑ Aplicando optimizaciones avanzadas (feature engineering, selecci√≥n de regresores, optimizaci√≥n bayesiana, calibraci√≥n de intervalos)...")
                            
                            with st.spinner("Este proceso puede tardar unos minutos mientras se buscan los par√°metros √≥ptimos..."):
                                # Aplicar todas las optimizaciones y obtener el modelo optimizado
                                model, optimization_results = optimizer.apply_advanced_optimizations(
                                    df=train_df,
                                    cve_df=cve_df,
                                    use_optimal_regressors=use_optimal_regressors,
                                    use_bayesian_optimization=use_bayesian_optimization,
                                    use_interval_calibration=use_interval_calibration,
                                    optimization_trials=optimization_trials,
                                    optimization_timeout=600  # 10 minutos m√°ximo
                                )
                                
                                # Actualizar el estado de las optimizaciones aplicadas
                                optimizations_applied = {
                                    'log_transform': use_log_transform,
                                    'optimal_regressors': use_optimal_regressors,
                                    'bayesian_optimization': use_bayesian_optimization,
                                    'interval_calibration': use_interval_calibration,
                                    'selected_regressors': [],
                                    'optimized_params': {}
                                }
                                
                                # Verificar si se aplic√≥ selecci√≥n √≥ptima de regresores
                                if 'regressors' in optimization_results:
                                    optimizations_applied['selected_regressors'] = optimization_results['regressors']
                                
                                # Verificar si se aplic√≥ optimizaci√≥n bayesiana
                                if 'params' in optimization_results:
                                    optimizations_applied['optimized_params'] = optimization_results['params']
                                
                                # Guardar el estado de las optimizaciones en la sesi√≥n
                                st.session_state.optimizations_applied = optimizations_applied

                                # Mostrar informaci√≥n sobre las optimizaciones aplicadas de forma m√°s clara
                                st.info("‚úÖ Optimizaciones Aplicadas:")
                                st.info(f"- log_transform: {optimizations_applied['log_transform']}")
                                st.info(f"- optimal_regressors: {optimizations_applied['optimal_regressors']}")
                                st.info(f"- bayesian_optimization: {optimizations_applied['bayesian_optimization']}")
                                st.info(f"- interval_calibration: {optimizations_applied['interval_calibration']}")

                                if optimizations_applied['selected_regressors']:
                                    st.info(f"- Regresores seleccionados: {', '.join(optimizations_applied['selected_regressors'])}")
                                else:
                                    st.info("- No se seleccionaron regresores espec√≠ficos")
                                
                                # Mostrar informaci√≥n sobre las optimizaciones aplicadas
                                st.info(f"Optimizaciones aplicadas: {optimizations_applied}")
                                
                                # Guardar en el estado de la sesi√≥n
                                st.session_state.prophet_model = model
                                st.session_state.optimizer = optimizer  # Guardar el optimizador para las predicciones
                                st.session_state.model_trained = True
                                
                                # Guardar los par√°metros optimizados para referencia
                                st.session_state.optimized_params = {
                                    'changepoint_prior_scale': changepoint_prior_scale,
                                    'seasonality_prior_scale': seasonality_prior_scale,
                                    'seasonality_mode': seasonality_mode,
                                    'interval_width': interval_width,
                                    'selected_regressors': optimization_results.get('selected_regressors', []),
                                    'transformation': 'log'
                                }
                                
                                st.success("‚úÖ Modelo optimizado y entrenado correctamente")
                                return model
                                
                        else:
                            # IMPLEMENTACI√ìN ORIGINAL - Sin cambios
                            # Crear un optimizer para manejar todas las optimizaciones
                            optimizer = ModelOptimizer(
                                df=train_df,
                                correlation_threshold=correlation_threshold,
                                vif_threshold=vif_threshold,
                                optimization_trials=optimization_trials
                            )
                            
                            # 1. Aplicar selecci√≥n √≥ptima de regresores si est√° habilitada
                            selected_regressors = []
                            if use_optimal_regressors and enable_regressors:
                                st.info("üîç Seleccionando regresores √≥ptimos...")
                                selected_regressors = optimizer.select_optimal_regressors()
                                
                                if selected_regressors:
                                    st.success(f"‚úÖ Regresores seleccionados: {', '.join(selected_regressors)}")
                                    # A√±adir los regresores al dataframe si hay alguno seleccionado
                                    train_df = optimizer.add_regressors_to_dataframe(train_df, selected_regressors)
                                else:
                                    st.warning(f"‚ö†Ô∏è No se encontraron regresores significativos (correlaci√≥n ‚â• {correlation_threshold}, VIF < {vif_threshold})")
                            
                            # 2. Aplicar optimizaci√≥n bayesiana si est√° habilitada
                            optimal_params = {}
                            if use_bayesian_optimization:
                                st.info("üîç Optimizando hiperpar√°metros con Bayesian Optimization...")
                                optimal_params = optimizer.optimize_hyperparameters(
                                    initial_params={
                                        'changepoint_prior_scale': changepoint_prior_scale,
                                        'seasonality_prior_scale': seasonality_prior_scale,
                                        'seasonality_mode': seasonality_mode
                                    }
                                )
                                
                                # Actualizar par√°metros con los mejores encontrados
                                if optimal_params:
                                    changepoint_prior_scale = optimal_params.get('changepoint_prior_scale', changepoint_prior_scale)
                                    seasonality_prior_scale = optimal_params.get('seasonality_prior_scale', seasonality_prior_scale)
                                    seasonality_mode = optimal_params.get('seasonality_mode', seasonality_mode)
                                    
                                    st.success(f"‚úÖ Mejores hiperpar√°metros encontrados: {optimal_params}")
                                else:
                                    st.warning("‚ö†Ô∏è No se pudieron optimizar los hiperpar√°metros, usando valores por defecto")
                            
                            # Entrenar el modelo con los par√°metros optimizados
                            st.info("üß† Entrenando modelo con configuraci√≥n optimizada...")
                            model = Prophet(
                                changepoint_prior_scale=changepoint_prior_scale,
                                seasonality_prior_scale=seasonality_prior_scale,
                                seasonality_mode=seasonality_mode,
                                interval_width=interval_width
                            )
                            
                            # A√±adir regresores al modelo si se seleccionaron
                            if use_optimal_regressors and enable_regressors and selected_regressors:
                                for regressor in selected_regressors:
                                    # Verificar que el regressor exista en el dataframe
                                    if regressor in train_df.columns:
                                        # Calcular prior scale basado en la correlaci√≥n
                                        prior_scale = optimizer.get_regressor_prior_scale(regressor)
                                        model.add_regressor(regressor, prior_scale=prior_scale)
                                        st.info(f"  - A√±adido regresor '{regressor}' con prior_scale={prior_scale:.2f}")
                            
                            # Entrenar modelo con los datos de entrenamiento
                            model.fit(train_df)
                            
                            # 3. Aplicar calibraci√≥n de intervalos si est√° habilitada
                            if use_interval_calibration:
                                st.info("üîç Calibrando intervalos de predicci√≥n...")
                                # Hacer una predicci√≥n sobre los datos de entrenamiento para calibrar
                                future = model.make_future_dataframe(periods=0)
                                
                                # A√±adir los regresores al dataframe futuro si est√°n habilitados
                                if use_optimal_regressors and enable_regressors and selected_regressors:
                                    for regressor in selected_regressors:
                                        if regressor in train_df.columns:
                                            future[regressor] = train_df[regressor].values
                                
                                forecast = model.predict(future)
                                
                                # Calibrar los intervalos
                                calibrated_model = optimizer.calibrate_intervals(
                                    model=model,
                                    actual_values=train_df['y'],
                                    predicted_values=forecast['yhat']
                                )
                                
                                # Usar el modelo calibrado
                                model = calibrated_model
                                st.success("‚úÖ Intervalos calibrados correctamente")
                            
                            # Guardar en el estado de la sesi√≥n
                            st.session_state.prophet_model = model
                            st.session_state.model_trained = True
                            
                            # Guardar los par√°metros optimizados para referencia
                            st.session_state.optimized_params = {
                                'changepoint_prior_scale': changepoint_prior_scale,
                                'seasonality_prior_scale': seasonality_prior_scale,
                                'seasonality_mode': seasonality_mode,
                                'interval_width': interval_width,
                                'selected_regressors': selected_regressors
                            }
                            
                            st.success("‚úÖ Modelo optimizado y entrenado correctamente")
                            return model
                        
                    except Exception as e:
                        import traceback
                        st.error(f"‚ö†Ô∏è Error en las optimizaciones avanzadas: {str(e)}")
                        st.code(traceback.format_exc())
                        st.warning("Continuando con el entrenamiento est√°ndar...")
                
                # =========================================================================
                # ENTRENAMIENTO EST√ÅNDAR (si no se usaron optimizaciones avanzadas o fallaron)
                # =========================================================================
                # Crear y entrenar modelo directamente con Prophet
                st.info("Entrenando modelo Prophet est√°ndar...")
                model = Prophet(
                    changepoint_prior_scale=changepoint_prior_scale,
                    seasonality_prior_scale=seasonality_prior_scale,
                    seasonality_mode=seasonality_mode,
                    interval_width=interval_width
                )
                
                # Entrenar el modelo con el DataFrame limpio
                model.fit(train_df)
                
                # Guardar en el estado de la sesi√≥n
                st.session_state.prophet_model = model
                st.session_state.model_trained = True
                
                st.success("‚úÖ Modelo entrenado correctamente")
                return model
            else:
                st.error("No hay datos preparados. Prepara los datos primero.")
                return None
    
    except Exception as e:
        st.error(f"Error al entrenar modelo: {str(e)}")
        st.session_state.model_trained = False
        
        # Mostrar informaci√≥n de depuraci√≥n
        if hasattr(st.session_state.forecaster, 'df_prophet') and st.session_state.forecaster.df_prophet is not None:
            st.write(f"Columnas en df_prophet: {st.session_state.forecaster.df_prophet.columns.tolist()}")
            
        return None

def make_forecast_wrapper(_self=None, periods=30, include_history=True):
    """
    Genera predicciones utilizando el modelo entrenado.
    
    Parameters:
    -----------
    periods : int
        N√∫mero de per√≠odos futuros a predecir
    include_history : bool
        Indica si incluir datos hist√≥ricos en la predicci√≥n
    
    Returns:
    --------
    pandas.DataFrame
        DataFrame con las predicciones
    """
    try:
        # Verificar si hay un modelo entrenado
        if 'model' not in st.session_state:
            st.error("‚ùå No hay un modelo entrenado. Por favor, entrene un modelo primero.")
            return None
        
        with st.spinner("Generando predicciones..."):
            # Obtener el modelo y los datos
            model = st.session_state.model
            df = st.session_state.get('df', None)
            use_log_transform = st.session_state.get('use_log_transform', False)
            
            # Obtener informaci√≥n sobre optimizaciones aplicadas
            if 'optimizations_applied' in st.session_state:
                # Usar las optimizaciones guardadas durante el entrenamiento
                optimizations_applied = st.session_state.optimizations_applied
                st.info(f"Usando optimizaciones aplicadas durante el entrenamiento: {optimizations_applied}")
            else:
                # Si no hay informaci√≥n guardada, crear un diccionario por defecto
                optimizations_applied = {
                    'log_transform': use_log_transform,
                    'optimal_regressors': st.session_state.get('use_optimal_regressors', False),
                    'bayesian_optimization': st.session_state.get('use_bayesian_optimization', False),
                    'interval_calibration': st.session_state.get('use_interval_calibration', False),
                    'selected_regressors': [],
                    'optimized_params': {}
                }
                st.warning("‚ö†Ô∏è No se encontraron optimizaciones guardadas. Usando valores por defecto.")
                st.info("Esto puede ocurrir si el modelo fue entrenado en una sesi√≥n anterior o si hubo un problema durante el entrenamiento.")
                st.info("Para resolver esto, vuelva a entrenar el modelo con las optimizaciones deseadas.")
            
            # Crear futuro para predicci√≥n de manera segura (evitando DatetimeArray)
            # No usamos model.make_future_dataframe porque puede causar errores
            if df is None:
                st.error("No hay datos de entrenamiento disponibles")
                return None
            
            # Crear dataframe futuro manualmente
            last_date = df['ds'].max()
            
            if include_history:
                # Incluir datos hist√≥ricos + futuros
                historical_dates = df['ds'].tolist()  # Convertir a lista para evitar problemas con DatetimeArray
                
                # Crear fechas futuras usando DateOffset (compatible con pandas actual)
                future_dates = []
                current_date = last_date
                for i in range(periods):
                    # Usar pd.DateOffset en lugar de adici√≥n directa
                    current_date = current_date + pd.DateOffset(days=1)
                    future_dates.append(current_date)
                
                # Combinar listas y ordenar
                all_dates = sorted(historical_dates + future_dates)
                future = pd.DataFrame({'ds': all_dates})
            else:
                # Solo fechas futuras
                future_dates = []
                current_date = last_date
                for i in range(periods):
                    # Usar pd.DateOffset en lugar de adici√≥n directa
                    current_date = current_date + pd.DateOffset(days=1)
                    future_dates.append(current_date)
                future = pd.DataFrame({'ds': future_dates})
            
            # Si hay regresores externos, asegurarse de que est√©n en el futuro
            if hasattr(model, 'extra_regressors') and model.extra_regressors:
                if df is not None and 'cve_count' in df.columns:
                    # Extender el regresor cve_count con su valor medio para fechas futuras
                    last_date = df['ds'].max()
                    future_dates_mask = future['ds'] > last_date
                    future_dates = future[future_dates_mask]
                    
                    if not future_dates.empty:
                        # Usar el promedio de los √∫ltimos 30 d√≠as como valor para fechas futuras
                        cutoff_date = last_date - pd.DateOffset(days=30)
                        last_30_days = df[df['ds'] > cutoff_date]
                        avg_cve = last_30_days['cve_count'].mean() if not last_30_days.empty else df['cve_count'].mean()
                        
                        # Asegurarse de que future tiene la columna cve_count
                        if 'cve_count' not in future.columns:
                            future['cve_count'] = np.nan
                        
                        # Asignar el valor promedio a las fechas futuras
                        future.loc[future_dates_mask, 'cve_count'] = avg_cve
            
            # Generar predicci√≥n de manera segura
            try:
                # Verificar si el modelo tiene un m√©todo predict propio
                st.info("Modelo entrenado correctamente, generando predicciones...")
                
                if hasattr(model, 'model') and hasattr(model.model, 'predict'):
                    # Caso 1: El modelo tiene una estructura anidada
                    forecast = model.model.predict(future)
                elif hasattr(model, 'predict') and callable(model.predict):
                    # Caso 2: El modelo tiene un m√©todo predict directo
                    # Verificar si el predict es el que espera el DataFrame o uno personalizado
                    import inspect
                    predict_sig = inspect.signature(model.predict)
                    
                    # Si el m√©todo predict acepta un dataframe como primer argumento
                    if len(predict_sig.parameters) >= 1:
                        forecast = model.predict(future)
                    else:
                        # Si parece ser el m√©todo personalizado con periods
                        forecast = model.predict(periods=periods, include_history=include_history)
                else:
                    st.error("No se puede determinar c√≥mo generar predicciones con este modelo")
                    return None
                
                # Guardar la predicci√≥n en la sesi√≥n
                st.session_state.forecast = forecast
                
                # Mostrar mensaje de √©xito
                st.success("‚úÖ Predicci√≥n generada correctamente.")
                
                # Mostrar resumen de la predicci√≥n
                _show_prediction_summary(forecast, model, use_log_transform, optimizations_applied)
                
                return forecast
            except Exception as e:
                st.error(f"Error al generar la predicci√≥n: {str(e)}")
                import traceback
                st.code(traceback.format_exc())
                return None
    
    except Exception as e:
        st.error(f"Error al generar la predicci√≥n: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return None


def _prepare_evaluation_parameters(df, cv_periods, initial, period, horizon, train_percentage):
    """
    Prepara los par√°metros para la evaluaci√≥n de modelos.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame con los datos
    cv_periods : int
        N√∫mero de per√≠odos para validaci√≥n
    initial : str
        Fecha inicial para la evaluaci√≥n
    period : int
        Per√≠odo entre evaluaciones
    horizon : int
        Horizonte de predicci√≥n
    train_percentage : float
        Porcentaje de datos para entrenamiento
        
    Returns:
    --------
    dict
        Diccionario con los par√°metros configurados para la evaluaci√≥n
    """
    # Si no se especifica horizonte, usar cv_periods
    if horizon is None:
        horizon = cv_periods
        
    # Si no se especifica period, usar 1/3 del horizonte
    if period is None:
        period = max(1, int(horizon / 3))
    
    # Calcular fecha de corte si initial es None
    if initial is None:
        total_days = (df['ds'].max() - df['ds'].min()).days
        train_days = int(total_days * train_percentage)
        cutoff_date = df['ds'].min() + pd.Timedelta(days=train_days)
        initial = cutoff_date.strftime('%Y-%m-%d')
    else:
        # Convertir a datetime si es string
        if isinstance(initial, str):
            cutoff_date = pd.to_datetime(initial)
        else:
            cutoff_date = initial
    
    # Verificar que la fecha de corte es v√°lida
    if cutoff_date > df['ds'].max() or cutoff_date <= df['ds'].min():
        st.error(f"Fecha de corte {cutoff_date} fuera del rango de datos ({df['ds'].min()} a {df['ds'].max()})")
        cutoff_date = df['ds'].min() + pd.Timedelta(days=int((df['ds'].max() - df['ds'].min()).days * 0.7))
        st.warning(f"Ajustando fecha de corte a {cutoff_date}")
    
    return {
        'initial': initial,
        'period': period,
        'horizon': horizon,
        'cutoff_date': cutoff_date
    }

def _perform_single_cutoff_evaluation(model, df, params):
    """
    Realiza evaluaci√≥n con un solo punto de corte.
    
    Parameters:
    -----------
    model : Prophet
        Modelo Prophet entrenado
    df : pandas.DataFrame
        DataFrame con los datos
    params : dict
        Par√°metros de evaluaci√≥n
        
    Returns:
    --------
    tuple
        (m√©tricas, predicciones)
    """
    cutoff_date = params['cutoff_date']
    horizon = params['horizon']
    
    # Dividir datos en entrenamiento y prueba
    train_df = df[df['ds'] <= cutoff_date].copy()
    test_df = df[df['ds'] > cutoff_date].copy()
    test_df = test_df[test_df['ds'] <= (cutoff_date + pd.Timedelta(days=horizon))].copy()
    
    # Verificar que hay datos de prueba suficientes
    if len(test_df) == 0:
        st.warning(f"No hay datos de prueba despu√©s de {cutoff_date}")
        test_end = cutoff_date + pd.Timedelta(days=horizon)
        st.info(f"Per√≠odo de prueba: {cutoff_date} a {test_end}")
        test_df = pd.DataFrame({
            'ds': pd.date_range(start=cutoff_date + pd.Timedelta(days=1), 
                              end=cutoff_date + pd.Timedelta(days=horizon), 
                              freq='D')
        })
        test_df['y'] = np.nan
    
    # Crear nuevo modelo con solo datos de entrenamiento
    test_model = Prophet(
        changepoint_prior_scale=model.changepoint_prior_scale,
        seasonality_prior_scale=model.seasonality_prior_scale,
        holidays_prior_scale=model.holidays_prior_scale,
        seasonality_mode=model.seasonality_mode,
        interval_width=model.interval_width
    )
    
    # A√±adir estacionalidades y regresores si es necesario
    if hasattr(model, 'seasonalities'):
        for name, params in model.seasonalities.items():
            test_model.add_seasonality(
                name=name,
                period=params['period'],
                fourier_order=params['fourier_order'],
                prior_scale=params['prior_scale'],
                mode=params['mode']
            )
    
    # A√±adir regresores al modelo si el modelo original los tiene
    if hasattr(model, 'extra_regressors') and model.extra_regressors:
        for name, params in model.extra_regressors.items():
            if name in train_df.columns:
                test_model.add_regressor(
                    name=name,
                    prior_scale=params['prior_scale'],
                    standardize=params['standardize'],
                    mode=params['mode']
                )
    
    # Entrenar modelo con datos de entrenamiento
    test_model.fit(train_df)
    
    # Generar futuro para per√≠odo de prueba
    future = pd.DataFrame({'ds': pd.date_range(start=cutoff_date + pd.Timedelta(days=1), 
                                          end=cutoff_date + pd.Timedelta(days=horizon), 
                                          freq='D')})
    
    # A√±adir regresores al futuro si es necesario
    if hasattr(model, 'extra_regressors') and model.extra_regressors:
        for name in model.extra_regressors:
            if name in test_df.columns:
                # A√±adir el regresor al futuro desde el df original
                future[name] = test_df[name]
    
    # Predecir con el modelo de prueba
    forecast = test_model.predict(future)
    
    # Filtrar las predicciones para el per√≠odo de prueba
    forecast_valid = forecast[forecast['ds'] <= (cutoff_date + pd.Timedelta(days=horizon))].copy()
    
    # Asegurar que las fechas est√°n en el mismo formato para la fusi√≥n
    test_df['ds'] = pd.to_datetime(test_df['ds'])
    forecast_valid['ds'] = pd.to_datetime(forecast_valid['ds'])

    # Fusionar datasets y verificar que no haya valores NaN
    test_with_preds = test_df.merge(forecast_valid[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], on='ds', how='inner')  # Usar inner join para mantener solo fechas que existen en ambos

    # Verificar si tenemos datos suficientes para calcular m√©tricas
    if len(test_with_preds) == 0:
        logger.warning("No hay coincidencia entre fechas de prueba y predicciones. Usando left join.")
        test_with_preds = test_df.merge(forecast_valid[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], 
                                    on='ds', how='left')

    # Verificar expl√≠citamente que tenemos valores y y yhat para el c√°lculo de m√©tricas
    valid_rows = ~test_with_preds['y'].isna() & ~test_with_preds['yhat'].isna()
    if not any(valid_rows):
        logger.error("No hay filas v√°lidas para calcular m√©tricas (y o yhat son NaN)")
        # Registrar informaci√≥n de diagn√≥stico
        logger.info(f"Filas en test_df: {len(test_df)}, filas en forecast_valid: {len(forecast_valid)}")
        logger.info(f"Fechas en test_df: {test_df['ds'].min()} a {test_df['ds'].max()}")
        logger.info(f"Fechas en forecast_valid: {forecast_valid['ds'].min()} a {forecast_valid['ds'].max()}")
    else:
        logger.info(f"Calculando m√©tricas con {sum(valid_rows)} filas v√°lidas de {len(test_with_preds)} totales")
    
    # Calcular m√©tricas
    metrics = _calculate_forecast_metrics(test_with_preds)
    
    return metrics, test_with_preds

def _perform_multi_cutoff_evaluation(model, df, params, max_iterations):
    """
    Realiza evaluaci√≥n con m√∫ltiples puntos de corte.
    
    Parameters:
    -----------
    model : Prophet
        Modelo Prophet entrenado
    df : pandas.DataFrame
        DataFrame con los datos
    params : dict
        Par√°metros de evaluaci√≥n
    max_iterations : int
        N√∫mero m√°ximo de iteraciones
        
    Returns:
    --------
    tuple
        (m√©tricas promedio, todas las m√©tricas, predicciones)
    """
    cutoff_date = params['cutoff_date']
    period = params['period']
    horizon = params['horizon']
    
    # Generar fechas de corte
    end_date = df['ds'].max() - pd.Timedelta(days=horizon)
    
    # Si la fecha de corte es posterior a end_date, ajustarla
    if cutoff_date > end_date:
        cutoff_date = end_date - pd.Timedelta(days=horizon)
        st.warning(f"Ajustando fecha de corte a {cutoff_date} para permitir evaluaci√≥n")
    
    cutoff_dates = [cutoff_date]
    current_date = cutoff_date
    
    # Generar fechas de corte adicionales
    for i in range(1, max_iterations):
        next_date = current_date + pd.Timedelta(days=period)
        if next_date > end_date:
            break
        cutoff_dates.append(next_date)
        current_date = next_date
    
    # Realizar evaluaci√≥n para cada fecha de corte
    all_metrics = []
    all_predictions = []
    
    for i, cutoff in enumerate(cutoff_dates):
        st.info(f"Evaluaci√≥n {i+1}/{len(cutoff_dates)}: Punto de corte {cutoff}")
        
        # Par√°metros para esta iteraci√≥n
        iteration_params = {
            'cutoff_date': cutoff,
            'period': period,
            'horizon': horizon
        }
        
        # Realizar evaluaci√≥n
        metrics, preds = _perform_single_cutoff_evaluation(model, df, iteration_params)
        
        # A√±adir identificador a las predicciones
        preds['iteration'] = i + 1
        preds['cutoff'] = cutoff
        
        all_metrics.append(metrics)
        all_predictions.append(preds)
    
    # Unir todas las predicciones
    all_predictions_df = pd.concat(all_predictions)
    
    # Calcular m√©tricas promedio
    avg_metrics = {
        'mae': np.mean([m['mae'] for m in all_metrics]),
        'rmse': np.mean([m['rmse'] for m in all_metrics]),
        'smape': np.mean([m['smape'] for m in all_metrics]),
        'coverage': np.mean([m['coverage'] for m in all_metrics]),
        'n_iterations': len(all_metrics)
    }
    
    return avg_metrics, all_metrics, all_predictions_df

def _calculate_forecast_metrics(df):
    """
    Calcula m√©tricas de rendimiento de las predicciones.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        DataFrame con valores reales y predicciones
        
    Returns:
    --------
    dict
        Diccionario con m√©tricas calculadas
    """
    # Asegurar que estamos usando el DataFrame correcto
    eval_df = df.copy()
    
    if not all(col in eval_df.columns for col in ['y', 'yhat']):
        logger.error(f"Columnas requeridas no encontradas. Columnas disponibles: {eval_df.columns.tolist()}")
        return {'error': 'El DataFrame debe contener columnas "y" y "yhat"'}
    
    try:
        # Eliminar filas con NaN en y o yhat
        eval_df = eval_df.dropna(subset=['y', 'yhat'])
        
        if len(eval_df) == 0:
            logger.error("Despu√©s de eliminar NaN, no quedan filas para evaluar")
            return {
                'mae': 0.0,  # Usar 0 en lugar de NaN para evitar errores en la UI
                'rmse': 0.0,
                'smape': 0.0,
                'coverage': 0.0,
                'interval_width_avg': 0.0,
                'interval_width_relative': 0.0,
                'n_points': 0,
                'error': "No hay datos v√°lidos para evaluar"
            }
        
        # Preparar datos para m√©tricas
        y_true = eval_df['y'].values
        y_pred = eval_df['yhat'].values
        
        # Verificar si existen las columnas de intervalos
        has_intervals = 'yhat_lower' in eval_df.columns and 'yhat_upper' in eval_df.columns
        
        interval_lower = None
        interval_upper = None
        
        if has_intervals:
            # Asegurar que no hay NaN en los intervalos
            mask = ~np.isnan(eval_df['yhat_lower']) & ~np.isnan(eval_df['yhat_upper'])
            if np.any(mask):
                interval_lower = eval_df.loc[mask, 'yhat_lower'].values
                interval_upper = eval_df.loc[mask, 'yhat_upper'].values
                
                # Verificar que los intervalos tienen el mismo tama√±o que y_true y y_pred
                if len(interval_lower) != len(y_true):
                    logger.warning(f"Tama√±os inconsistentes despu√©s de eliminar NaN: {len(interval_lower)} vs {len(y_true)}")
                    # Ajustar y_true y y_pred para que coincidan con los intervalos
                    mask_indices = np.where(mask)[0]
                    if len(mask_indices) > 0:
                        y_true = eval_df.loc[mask, 'y'].values
                        y_pred = eval_df.loc[mask, 'yhat'].values
            else:
                logger.warning("Todos los intervalos contienen valores NaN, no se usar√°n intervalos")
                has_intervals = False
        
        # Intentar usar el m√≥dulo centralizado de m√©tricas
        try:
            # Calcular m√©tricas utilizando la funci√≥n centralizada
            metrics = calculate_metrics(
                y_true=y_true, 
                y_pred=y_pred,
                interval_lower=interval_lower if has_intervals else None,
                interval_upper=interval_upper if has_intervals else None
            )
            
            # Verificar si 'metrics' contiene un campo 'error'
            if 'error' in metrics:
                logger.warning(f"Error al calcular m√©tricas centralizadas: {metrics['error']}")
                # Calcular manualmente como respaldo
                raise ValueError(metrics['error'])
            
            # A√±adir n√∫mero de puntos a las m√©tricas
            metrics['n_points'] = len(y_true)
            
            # Nota: No multiplicar SMAPE por 100, ya que calculate_metrics ya lo devuelve en porcentaje
            
            # Verificar y ajustar los valores para evitar NaN
            for key in ['mae', 'rmse', 'smape', 'r2', 'dir_acc', 'coverage']:
                if key in metrics and (np.isnan(metrics[key]) or metrics[key] is None):
                    logger.warning(f"M√©trica {key} es NaN, sustituyendo por 0")
                    metrics[key] = 0.0
            
            # Si la cobertura viene en proporci√≥n (0-1), convertirla a porcentaje (0-100)
            if 'coverage' in metrics and metrics['coverage'] <= 1.0:
                metrics['coverage'] = metrics['coverage'] * 100
                
            # Calcular m√©tricas adicionales de intervalos si no est√°n incluidas
            if 'interval_width_avg' not in metrics and has_intervals:
                interval_widths = interval_upper - interval_lower
                metrics['interval_width_avg'] = float(np.mean(interval_widths))
                
                yhat_mean = np.mean(y_pred)
                if abs(yhat_mean) > 1e-8:
                    metrics['interval_width_relative'] = float(metrics['interval_width_avg'] / yhat_mean * 100)
                else:
                    metrics['interval_width_relative'] = 0.0
            elif not has_intervals:
                metrics['interval_width_avg'] = 0.0
                metrics['interval_width_relative'] = 0.0
                
        except Exception as e:
            logger.warning(f"Error al usar el m√≥dulo centralizado: {str(e)}. Usando c√°lculo manual.")
            
            # Calcular m√©tricas b√°sicas manualmente como respaldo
            try:
                from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
                
                mae = mean_absolute_error(y_true, y_pred)
                rmse = np.sqrt(mean_squared_error(y_true, y_pred))
                r2 = r2_score(y_true, y_pred)
            except Exception as sklearn_error:
                logger.warning(f"Error al usar sklearn: {str(sklearn_error)}. Usando c√°lculo num√©rico directo.")
                mae = np.mean(np.abs(y_true - y_pred))
                rmse = np.sqrt(np.mean((y_true - y_pred)**2))
                r2 = 0.0
            
            # Calcular SMAPE manualmente
            try:
                # Intentar usar la funci√≥n centralizada de SMAPE
                smape = calculate_smape(y_true, y_pred)
            except Exception as smape_error:
                logger.warning(f"Error al calcular SMAPE centralizado: {str(smape_error)}. Usando f√≥rmula directa.")
                # C√°lculo manual como respaldo
                epsilon = 1e-8
                denominator = np.abs(y_true) + np.abs(y_pred) + epsilon
                smape = 2.0 * np.mean(np.abs(y_true - y_pred) / denominator) * 100
            
            # Calcular cobertura manualmente
            coverage = 0.0
            interval_width_avg = 0.0
            interval_width_relative = 0.0
            
            if has_intervals:
                in_range = ((y_true >= interval_lower) & (y_true <= interval_upper))
                coverage = np.mean(in_range) * 100
                
                interval_widths = interval_upper - interval_lower
                interval_width_avg = np.mean(interval_widths)
                
                yhat_mean = np.mean(y_pred)
                if abs(yhat_mean) > 1e-8:
                    interval_width_relative = interval_width_avg / yhat_mean * 100
            
            # Crear diccionario de m√©tricas manual
            metrics = {
                'mae': float(mae),
                'rmse': float(rmse),
                'smape': float(smape),
                'r2': float(r2),
                'coverage': float(coverage),
                'interval_width_avg': float(interval_width_avg),
                'interval_width_relative': float(interval_width_relative),
                'n_points': len(y_true)
            }
            
            # Verificar y reemplazar NaN con 0
            for key in metrics:
                if isinstance(metrics[key], (int, float)) and np.isnan(metrics[key]):
                    metrics[key] = 0.0
        
        # Calcular puntuaciones de anomal√≠a si hay datos suficientes
        if len(y_true) > 10:
            try:
                anomaly_scores = calculate_anomaly_score(y_true, y_pred)
                
                # A√±adir puntuaci√≥n media de anomal√≠a y m√°xima
                metrics['anomaly_score_mean'] = float(np.mean(anomaly_scores))
                metrics['anomaly_score_max'] = float(np.max(anomaly_scores))
                
                # Calcular porcentaje de puntos que son anomal√≠as (umbral arbitrario de 2.0)
                anomaly_threshold = 2.0
                metrics['anomaly_percentage'] = float(np.mean(anomaly_scores > anomaly_threshold) * 100)
            except Exception as e:
                logger.warning(f"Error al calcular anomal√≠as: {str(e)}")
                # Asignar valores predeterminados para evitar errores
                metrics['anomaly_score_mean'] = 0.0
                metrics['anomaly_score_max'] = 0.0
                metrics['anomaly_percentage'] = 0.0
        
        # Verificar cambios en patrones de ataque
        if len(y_true) > 20:
            try:
                pattern_change = detect_attack_pattern_change(y_true, y_pred)
                metrics['pattern_change_detected'] = pattern_change
            except Exception as e:
                logger.warning(f"Error al detectar cambios de patr√≥n: {str(e)}")
                metrics['pattern_change_detected'] = False
        
        # Logging para depuraci√≥n
        logger.info(
            f"M√©tricas calculadas: MAE={metrics.get('mae', 0):.4f}, "
            f"RMSE={metrics.get('rmse', 0):.4f}, "
            f"SMAPE={metrics.get('smape', 0):.2f}%, "
            f"Cobertura={metrics.get('coverage', 0):.1f}%"
        )
            
        return metrics
    except Exception as e:
        logger.error(f"Error al calcular m√©tricas: {traceback.format_exc()}")
        return {
            'mae': 0.0,  # Usar 0 en lugar de NaN para evitar problemas en la UI
            'rmse': 0.0,
            'smape': 0.0,
            'coverage': 0.0,
            'interval_width_avg': 0.0,
            'interval_width_relative': 0.0,
            'n_points': 0,
            'error': str(e)
        }

def _display_evaluation_results(
    metrics: Dict[str, Any],
    all_metrics: Optional[List[Dict[str, Any]]],
    df: pd.DataFrame,
    test_predictions: pd.DataFrame,
    multi_eval: bool = False,
    use_log_transform: bool = False
) -> Optional[Dict[str, float]]:
    """
    Muestra los resultados de la evaluaci√≥n del modelo.

    Parameters:
    -----------
    metrics : dict
        Diccionario con m√©tricas calculadas
    all_metrics : list
        Lista de m√©tricas para m√∫ltiples puntos de corte
    df : pandas.DataFrame
        DataFrame con los datos completos
    test_predictions : pandas.DataFrame
        DataFrame con predicciones de prueba (columnas: ds, yhat, yhat_lower, yhat_upper)
    multi_eval : bool
        Indica si se realiz√≥ evaluaci√≥n con m√∫ltiples puntos de corte
    use_log_transform : bool
        Indica si se aplic√≥ transformaci√≥n logar√≠tmica a los datos
    
    Returns:
    --------
    dict
        Diccionario con las m√©tricas de evaluaci√≥n o None en caso de error
    """
    # --- Validaciones iniciales ---
    if metrics is None:
        st.error("No hay m√©tricas disponibles para mostrar.")
        return None

    if not isinstance(df, pd.DataFrame) or df.empty:
        st.error("El DataFrame de datos est√° vac√≠o o no es v√°lido.")
        return metrics

    if not isinstance(test_predictions, pd.DataFrame) or test_predictions.empty:
        st.error("El DataFrame de predicciones est√° vac√≠o o no es v√°lido.")
        return metrics

    # Columnas m√≠nimas requeridas
    for col in ['ds', 'y']:
        if col not in df.columns:
            st.error(f"Falta columna '{col}' en los datos: {df.columns.tolist()}")
            return metrics
    if 'ds' not in test_predictions.columns or 'yhat' not in test_predictions.columns:
        st.error(f"Las predicciones deben contener 'ds' y 'yhat': {test_predictions.columns.tolist()}")
        return metrics

    # Inversi√≥n de log transform si corresponde
    if use_log_transform:
        df = df.copy()
        test_predictions = test_predictions.copy()
        # y
        df['y'] = np.expm1(df['y'])
        # yhat y bounds
        test_predictions['yhat'] = np.expm1(test_predictions['yhat'])
        if 'yhat_lower' in test_predictions:
            test_predictions['yhat_lower'] = np.expm1(test_predictions['yhat_lower'])
        if 'yhat_upper' in test_predictions:
            test_predictions['yhat_upper'] = np.expm1(test_predictions['yhat_upper'])

    # --- Mostrar m√©tricas en Streamlit ---
    st.success("‚úÖ Evaluaci√≥n del modelo completada")
    st.markdown("### M√©tricas de Rendimiento")

    cols = st.columns(4)
    st.metric(label="Amplitud Promedio", value=f"{metrics.get('interval_width_avg', 0):.2f}", help="Amplitud media de los intervalos de predicci√≥n. Valores m√°s bajos indican mayor precisi√≥n.")
    st.metric(label="Cobertura Intervalos (%)", value=f"{metrics.get('coverage', 0):.1f}%", help="% de valores reales en intervalo.")
    st.metric(label="Error (SMAPE)", value=f"{metrics.get('smape', 0):.1f}%", help="Error porcentual medio sim√©trico. Valores m√°s bajos indican mejor precisi√≥n.")
    st.metric(label="Iteraciones", value=metrics.get('iterations', 1), help="Cantidad de iteraciones realizadas.")

    # Tabla de multi-evaluaci√≥n
    if multi_eval and all_metrics:
        st.markdown("#### M√©tricas por Punto de Corte")
        df_met = pd.DataFrame(all_metrics)
        # Seleccionar columnas clave si existen
        cols_show = [c for c in ['iteration', 'cutoff', 'mae', 'rmse', 'smape', 'coverage', 'interval_width_avg'] if c in df_met.columns]
        df_met = df_met.sort_values('cutoff') if 'cutoff' in df_met.columns else df_met
        st.dataframe(df_met[cols_show])

    # --- Gr√°fico de Backtesting ---
    st.markdown("### Visualizaci√≥n de Backtesting")
    try:
        start = test_predictions['ds'].min()
        if pd.isna(start):
            st.warning("Fecha m√≠nima de predicciones inv√°lida.")
            return metrics

        # Datos de entrenamiento y validaci√≥n
        train = df[df['ds'] < start]
        valid = df.merge(test_predictions[['ds']], on='ds', how='inner')

        fig = go.Figure()
        if not train.empty:
            fig.add_trace(go.Scatter(x=train['ds'], y=train['y'], mode='lines', name='Entrenamiento'))
        if not valid.empty:
            fig.add_trace(go.Scatter(x=valid['ds'], y=valid['y'], mode='lines', name='Valores Reales'))

        # Predicci√≥n
        fig.add_trace(go.Scatter(x=test_predictions['ds'], y=test_predictions['yhat'], mode='lines', name='Predicci√≥n'))

        # Intervalo
        if 'yhat_lower' in test_predictions and 'yhat_upper' in test_predictions:
            fig.add_trace(go.Scatter(
                x=pd.concat([test_predictions['ds'], test_predictions['ds'][::-1]]),
                y=pd.concat([test_predictions['yhat_upper'], test_predictions['yhat_lower'][::-1]]),
                fill='toself', name='Intervalo 95%', fillcolor='rgba(255,0,0,0.2)', line=dict(width=0)
            ))

        fig.update_layout(title='Backtesting: Predicci√≥n vs Real', xaxis_title='Fecha', yaxis_title='Valor', hovermode='x unified', template='plotly_white')
        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Error al generar gr√°fico de backtesting: {e}")
        return metrics

    return metrics


def train_model_wrapper(
    df: Optional[pd.DataFrame] = None,
    use_regressor: bool = True,
    use_optimal_regressors: bool = True,
    use_bayesian_optimization: bool = False,
    use_interval_calibration: bool = True,
    optimization_trials: int = 10,
    correlation_threshold: float = 0.1,
    vif_threshold: float = 5.0,
    seasonality_mode: str = 'multiplicative',
    use_log_transform: bool = True,
    changepoint_prior_scale: float = 0.05,
    seasonality_prior_scale: float = 10.0,
    holidays_prior_scale: float = 10.0,
    regressors_prior_scale: float = 0.1,
    interval_width: float = 0.6,
    changepoint_range: float = 0.8,
    n_changepoints: int = 25,
    use_detected_changepoints: bool = False,
    daily_seasonality: bool = False,
    weekly_seasonality: bool = True,
    yearly_seasonality: bool = True,
    calibrate_intervals: bool = True
) -> tuple:
    """
    Wrapper para entrenar el modelo Prophet a trav√©s de la UI de Streamlit
    
    Args:
        df: DataFrame con datos de entrenamiento (opcional, si no se proporciona se obtiene de la sesi√≥n)
        use_regressor: Si usar regresores externos
        use_optimal_regressors: Si usar selecci√≥n autom√°tica de regresores √≥ptimos
        use_bayesian_optimization: Si usar optimizaci√≥n bayesiana para hiperpar√°metros
        use_interval_calibration: Si usar calibraci√≥n de intervalos durante el entrenamiento
        optimization_trials: N√∫mero de pruebas para optimizaci√≥n bayesiana
        correlation_threshold: Umbral de correlaci√≥n para selecci√≥n de regresores
        vif_threshold: Umbral de VIF para controlar multicolinealidad entre regresores
        seasonality_mode: Modo de estacionalidad ('additive' o 'multiplicative')
        use_log_transform: Si aplicar transformaci√≥n logar√≠tmica
        changepoint_prior_scale: Escala previa de puntos de cambio
        seasonality_prior_scale: Escala previa de estacionalidad
        holidays_prior_scale: Escala previa de festivos
        regressors_prior_scale: Escala previa de regresores
        interval_width: Ancho del intervalo de predicci√≥n
        changepoint_range: Rango de puntos de cambio
        n_changepoints: N√∫mero de puntos de cambio
        use_detected_changepoints: Si usar detecci√≥n autom√°tica de changepoints
        daily_seasonality: Si usar estacionalidad diaria
        weekly_seasonality: Si usar estacionalidad semanal
        yearly_seasonality: Si usar estacionalidad anual
        calibrate_intervals: Si calibrar los intervalos de predicci√≥n
        
    Returns:
    --------
    Tupla con (modelo entrenado, DataFrame de predicci√≥n)
    """
    from .models.prophet_model import RansomwareProphetModel
    from .features.regressors import RegressorGenerator
    
    # Inicializar logger
    logger = logging.getLogger(__name__)
    logger.info("Iniciando entrenamiento de modelo")
    
    # Si no se proporciona df, intentar obtenerlo de la sesi√≥n de Streamlit
    if df is None:
        logger.info("No se proporcion√≥ DataFrame, intentando obtenerlo de la sesi√≥n")
        if 'df_prophet' in st.session_state:
            df = st.session_state.df_prophet
            logger.info(f"DataFrame obtenido de sesi√≥n: {len(df)} filas")
        else:
            st.error("No hay datos para entrenar. Por favor, cargue datos primero.")
            return None, None
    
    # Verificar si hay datos suficientes
    if df is None or len(df) < 10:
        st.error("Datos insuficientes para entrenar modelo")
        return None, None
    
    # Configurar par√°metros del modelo
    model_config = {
        'seasonality_mode': seasonality_mode,
        'use_log_transform': use_log_transform,
        'changepoint_prior_scale': changepoint_prior_scale,
        'seasonality_prior_scale': seasonality_prior_scale,
        'holidays_prior_scale': holidays_prior_scale,
        'regressors_prior_scale': regressors_prior_scale,
        'interval_width': interval_width,
        'changepoint_range': changepoint_range,
        'n_changepoints': n_changepoints,
        'use_detected_changepoints': use_detected_changepoints,
        'daily_seasonality': daily_seasonality,
        'weekly_seasonality': weekly_seasonality,
        'yearly_seasonality': yearly_seasonality
    }
    
    # Cargar regresores si se solicita
    regressors = None
    if use_regressor:
        try:
            logger.info("Configurando regresores")
            
            # Inicializar generador de regresores
            if 'regressors' not in st.session_state or st.session_state.regressors is None:
                st.session_state.regressors = RegressorGenerator()
                
            regressors = st.session_state.regressors
            
            # Cargar datos de CVE mediante el dataframe si est√° disponible en la sesi√≥n
            cve_df = None
            cve_file = 'modeling/cve_diarias_regresor_prophet.csv'
            
            if hasattr(st.session_state, 'cve_file') and st.session_state.cve_file:
                cve_file = st.session_state.cve_file
            
            # Intentar obtener df_cve del forecaster si existe
            if 'forecaster' in st.session_state and hasattr(st.session_state.forecaster, 'df_cve'):
                cve_df = st.session_state.forecaster.df_cve
            else:
                # Cargar datos CVE manualmente
                try:
                    cve_df = pd.read_csv(cve_file)
                    if 'fecha' in cve_df.columns:
                        cve_df = cve_df.rename(columns={'fecha': 'ds'})
                    # Convertir a datetime
                    cve_df['ds'] = pd.to_datetime(cve_df['ds'])
                except Exception as e:
                    logger.warning(f"No se pudieron cargar datos de CVE: {str(e)}")
                    
            # Seleccionar autom√°ticamente los mejores regresores si se solicita
            if use_optimal_regressors:
                logger.info("Seleccionando regresores √≥ptimos")
                df_with_date = df.copy()
                if 'ds' not in df_with_date.columns:
                    if 'date' in df_with_date.columns:
                        df_with_date = df_with_date.rename(columns={'date': 'ds'})
                    elif 'fecha' in df_with_date.columns:
                        df_with_date = df_with_date.rename(columns={'fecha': 'ds'})
                
                # A√±adir los datos de CVE como regresores al DataFrame de entrenamiento
                if cve_df is not None and not cve_df.empty:
                    try:
                        # Usar el m√©todo correcto para a√±adir regresores externos
                        df_with_date = regressors.add_external_regressors(df_with_date, cve_data=cve_df)
                        # Actualizar df para que incluya los regresores
                        df = df_with_date
                    except Exception as e:
                        logger.error(f"Error al a√±adir regresores externos: {str(e)}")
                
                try:
                    optimal_regressors = regressors.select_optimal_regressors(
                        df_with_date, target_col='y', 
                        correlation_threshold=correlation_threshold,
                        vif_threshold=vif_threshold
                    )
                    
                    if optimal_regressors and len(optimal_regressors) > 0:
                        logger.info(f"Seleccionados {len(optimal_regressors)} regresores √≥ptimos")
                        regressors.set_active_regressors(optimal_regressors)
                    else:
                        logger.warning("No se encontraron regresores √≥ptimos")
                        use_regressor = False
                except Exception as e:
                    logger.error(f"Error en selecci√≥n de regresores: {str(e)}")
                    use_regressor = False
            else:
                # Usar todos los regresores disponibles
                logger.info("Usando todos los regresores disponibles (sin optimizaci√≥n)")
                
                # Verificar que hay regresores disponibles
                available_regressors = regressors.get_available_regressors()
                if available_regressors and len(available_regressors) > 0:
                    regressors.set_active_regressors(available_regressors)
                    logger.info(f"Usando {len(available_regressors)} regresores disponibles")
                else:
                    logger.warning("No hay regresores disponibles")
                    use_regressor = False
        except Exception as e:
            st.error(f"Error al entrenar el modelo: {str(e)}")
            logger.error(f"Error en train_model_wrapper: {str(e)}")
            import traceback
            logger.error(traceback.format_exc())
            return None, None

    # Entrenar modelo
    try:
        with st.spinner("Entrenando modelo Prophet..."):
            # Inicializar modelo
            model = RansomwareProphetModel()
            
            # Si se solicita optimizaci√≥n bayesiana, ejecutarla antes de entrenar
            if use_bayesian_optimization:
                st.info("üîÑ Realizando optimizaci√≥n bayesiana...")
                # Implementaci√≥n pendiente de optimizaci√≥n bayesiana
                pass
            
            # Entrenar modelo con los datos proporcionados
            with st.spinner(f"Entrenando modelo con {len(df)} filas de datos..."):
                try:
                    # Primero crear el modelo Prophet interno con los par√°metros configurados
                    model.create_model(
                        changepoint_prior_scale=model_config.get('changepoint_prior_scale', 0.05),
                        seasonality_prior_scale=model_config.get('seasonality_prior_scale', 10.0),
                        seasonality_mode=model_config.get('seasonality_mode', 'multiplicative'),
                        interval_width=model_config.get('interval_width', 0.8),
                        n_changepoints=model_config.get('n_changepoints', 25)
                    )
                except ValueError as e:
                    if "holidays must be a DataFrame" in str(e):
                        # El error es por el formato de holidays, creamos manualmente el modelo Prophet
                        st.warning("Ajustando configuraci√≥n de holidays para compatibilidad...")
                        model.model = Prophet(
                            changepoint_prior_scale=model_config.get('changepoint_prior_scale', 0.05),
                            seasonality_prior_scale=model_config.get('seasonality_prior_scale', 10.0),
                            holidays_prior_scale=model_config.get('holidays_prior_scale', 10.0),
                            seasonality_mode=model_config.get('seasonality_mode', 'multiplicative'),
                            interval_width=model_config.get('interval_width', 0.8),
                            n_changepoints=model_config.get('n_changepoints', 25)
                        )
                        # Guardar par√°metros para referencia
                        model.params = model_config
                    else:
                        # Si es otro tipo de error, lo propagamos
                        raise
                
                # A√±adir regresores si est√°n disponibles
                if use_regressor and regressors is not None and len(regressors) > 0:
                    try:
                        regressor_count = 0
                        for regressor_name in regressors:
                            if regressor_name in df.columns:
                                model.model.add_regressor(regressor_name)
                                regressor_count += 1
                        
                        if regressor_count > 0:
                            st.info(f"üîÑ Usando {regressor_count} regresores externos")
                    except Exception as e:
                        logger.error(f"Error al a√±adir regresores: {str(e)}")
                        st.warning(f"Error al configurar regresores: {str(e)}")
                
                # Guardar datos de entrenamiento para futuras referencias
                model.train_data = df
                
                # Entrenar el modelo con los datos proporcionados
                model.model.fit(df)
                
                # A√±adir m√©todos de compatibilidad al modelo para compatibilidad con c√≥digo existente
                import types
                
                # M√©todo make_future_dataframe para compatibilidad
                def make_future_dataframe(self, periods=30, freq='D', include_history=True):
                    """M√©todo de compatibilidad para crear dataframe futuro"""
                    if not hasattr(self, 'train_data') or self.train_data is None:
                        raise ValueError("No hay datos de entrenamiento disponibles")
                    
                    # Usamos DateOffset en lugar de operaciones aritm√©ticas directas 
                    # para evitar el error con DatetimeArray
                    if include_history:
                        # Incluir datos hist√≥ricos
                        # Usar tolist() para evitar problemas con DatetimeArray
                        historical_dates = self.train_data['ds'].tolist()
                        
                        # Calcular el √∫ltimo d√≠a y crear fechas futuras usando DateOffset
                        last_date = self.train_data['ds'].max()
                        future_dates = []
                        current_date = last_date
                        for i in range(periods):
                            # Usar pd.DateOffset en lugar de adici√≥n directa
                            current_date = current_date + pd.DateOffset(days=1)
                            future_dates.append(current_date)
                        
                        # Combinar fechas hist√≥ricas y futuras
                        all_dates = sorted(historical_dates + future_dates)
                        future_df = pd.DataFrame({'ds': all_dates})
                    else:
                        # Solo fechas futuras
                        last_date = self.train_data['ds'].max()
                        future_dates = []
                        current_date = last_date
                        for i in range(periods):
                            # Usar pd.DateOffset en lugar de adici√≥n directa
                            current_date = current_date + pd.DateOffset(days=1)
                            future_dates.append(current_date)
                        future_df = pd.DataFrame({'ds': future_dates})
                    
                    return future_df
                
                # M√©todo forecast para compatibilidad
                def forecast_method(self, df=None, periods=30, include_history=True):
                    """M√©todo de compatibilidad para forecast/predict"""
                    # Si no se proporciona un DataFrame, crear uno compatible
                    if df is None:
                        # Generar dataframe futuro manualmente para evitar problemas con DatetimeArray
                        if not hasattr(self, 'train_data') or self.train_data is None:
                            raise ValueError("No hay datos de entrenamiento disponibles")
                        
                        last_date = self.train_data['ds'].max()
                        
                        if include_history:
                            # Obtener las fechas hist√≥ricas como lista (no como DatetimeArray)
                            # para evitar problemas de compatibilidad
                            historical_dates = self.train_data['ds'].tolist()
                            
                            # Crear fechas futuras usando DateOffset (compatible con versiones recientes)
                            future_dates = []
                            current_date = last_date
                            for i in range(periods):
                                # Usar pd.DateOffset en lugar de adici√≥n directa
                                current_date = current_date + pd.DateOffset(days=1)
                                future_dates.append(current_date)
                            
                            # Combinar ambas listas y ordenar
                            all_dates = sorted(historical_dates + future_dates)
                            df = pd.DataFrame({'ds': all_dates})
                        else:
                            # Solo fechas futuras usando DateOffset
                            future_dates = []
                            current_date = last_date
                            for i in range(periods):
                                # Usar pd.DateOffset en lugar de adici√≥n directa
                                current_date = current_date + pd.DateOffset(days=1)
                                future_dates.append(current_date)
                            df = pd.DataFrame({'ds': future_dates})
                    
                    # Ahora que tenemos un DataFrame v√°lido, hacer la predicci√≥n
                    return self.model.predict(df)
                
                # M√©todo predict como alias para forecast
                def predict_method(self, df=None, periods=30, include_history=True):
                    """Alias para forecast_method"""
                    return forecast_method(self, df, periods, include_history)
                
                # A√±adir los m√©todos al modelo
                model.make_future_dataframe = types.MethodType(make_future_dataframe, model)
                model.forecast = types.MethodType(forecast_method, model)
                model.predict = types.MethodType(predict_method, model)
            
            # Hacer predicci√≥n para mostrar resultados
            with st.spinner("Generando pron√≥stico..."):
                # Crear dataframe futuro para predicci√≥n
                future = pd.DataFrame({'ds': pd.date_range(start=df['ds'].max(), periods=31)[1:]})
                
                # Si hay regresores, a√±adirlos al dataframe futuro
                if use_regressor and regressors is not None and len(regressors) > 0:
                    for regressor_name in regressors:
                        if regressor_name in df.columns:
                            # Usar el √∫ltimo valor del regresor para predicci√≥n
                            future[regressor_name] = df[regressor_name].iloc[-1]
                
                # Generar predicci√≥n
                forecast = model.model.predict(future)
                
                # Calibrar intervalos si se solicita
                if calibrate_intervals and use_interval_calibration:
                    try:
                        if hasattr(model, 'calibrate_intervals'):
                            forecast = model.calibrate_intervals(df, forecast)
                    except Exception as e:
                        logger.error(f"Error al calibrar intervalos: {str(e)}")
            
            # Guardar el modelo en la sesi√≥n de Streamlit
            st.session_state.prophet_model = model
            st.session_state.prophet_forecast = forecast
            
            return model, forecast
            
    except Exception as e:
        logger.error(f"Error en entrenamiento: {str(e)}")
        st.error(f"Error en entrenamiento: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        st.error(traceback.format_exc())
        
        return None, None

def plot_forecast_wrapper():
    """
    Crea una visualizaci√≥n Plotly de la predicci√≥n almacenada en session_state.
    
    Returns:
        Figura Plotly con la visualizaci√≥n o None si hay un error
    """
    try:
        # Verificar si hay una predicci√≥n disponible
        if 'forecast' not in st.session_state:
            logger.error("No hay predicci√≥n disponible en session_state")
            return None
            
        forecast = st.session_state.forecast
        
        # Verificar que forecast no sea None
        if forecast is None:
            logger.error("La predicci√≥n en session_state es None")
            return None
            
        # Verificar que forecast sea un DataFrame
        if not isinstance(forecast, pd.DataFrame):
            logger.error(f"La predicci√≥n no es un DataFrame, es {type(forecast)}")
            return None
            
        # Verificar que forecast no est√© vac√≠o
        if forecast.empty:
            logger.error("El DataFrame de predicci√≥n est√° vac√≠o")
            return None
            
        # Imprimir las columnas disponibles para diagn√≥stico
        logger.info(f"Columnas en forecast: {list(forecast.columns)}")
        
        # Verificar que el DataFrame tenga las columnas necesarias
        required_cols = ['ds', 'yhat']
        missing_cols = [col for col in required_cols if col not in forecast.columns]
        if missing_cols:
            logger.error(f"Faltan columnas necesarias en el DataFrame de predicci√≥n: {missing_cols}")
            return None
        
        try:
            # Crear figura con subplots
            fig = make_subplots(
                rows=2, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.1,
                subplot_titles=("Predicci√≥n de ataques ransomware", "Componentes")
            )
            
            # A√±adir datos hist√≥ricos
            if 'df_prophet' in st.session_state and st.session_state.df_prophet is not None:
                fig.add_trace(
                    go.Scatter(
                        x=st.session_state.df_prophet['ds'],
                        y=st.session_state.df_prophet['y'],
                        mode='markers',
                        name='Datos hist√≥ricos',
                        marker=dict(color='#FF9F1C', size=8)  # Naranja brillante
                    ),
                    row=1, col=1
                )
            
            # Predicci√≥n
            fig.add_trace(
                go.Scatter(
                    x=forecast['ds'],
                    y=forecast['yhat'],
                    mode='lines',
                    name='Predicci√≥n',
                    line=dict(color='blue', width=3)  # Aumentado ancho de l√≠nea
                ),
                row=1, col=1
            )
            
            # Marcar √°rea futura
            if 'df_prophet' in st.session_state and st.session_state.df_prophet is not None:
                future_mask = ~forecast['ds'].isin(st.session_state.df_prophet['ds'])
                if future_mask.sum() > 0:
                    fig.add_trace(
                        go.Scatter(
                            x=forecast.loc[future_mask, 'ds'],
                            y=forecast.loc[future_mask, 'yhat'],
                            mode='lines',
                            name='Predicci√≥n futura',
                            line=dict(color='red', width=4)  # Aumentado ancho de l√≠nea de 2.5 a 4
                        ),
                        row=1, col=1
                    )
            
            # A√±adir intervalos de confianza
            if 'yhat_lower' in forecast.columns and 'yhat_upper' in forecast.columns:
                fig.add_trace(
                    go.Scatter(
                        x=forecast['ds'],
                        y=forecast['yhat_upper'],
                        mode='lines',
                        name='L√≠mite superior',
                        line=dict(width=0),
                        showlegend=False
                    ),
                    row=1, col=1
                )
                
                fig.add_trace(
                    go.Scatter(
                        x=forecast['ds'],
                        y=forecast['yhat_lower'],
                        mode='lines',
                        name='Intervalo de confianza',
                        line=dict(width=0),
                        fill='tonexty',
                        fillcolor='rgba(0, 0, 255, 0.3)'  # Aumentado opacidad de 0.2 a 0.3
                    ),
                    row=1, col=1
                )
            
            # A√±adir componentes - solo tendencia
            if 'trend' in forecast.columns:
                fig.add_trace(
                    go.Scatter(
                        x=forecast['ds'],
                        y=forecast['trend'],
                        mode='lines',
                        name='Tendencia',
                        line=dict(color='green', width=3)  # Aumentado ancho de l√≠nea de 2 a 3
                    ),
                    row=2, col=1
                )
            
            # Actualizar dise√±o
            fig.update_layout(
                height=600,  # Reducido para mejor proporci√≥n
                width=1200,  # Un poco m√°s ancho
                hovermode='x unified',
                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5),
                template='plotly_white',
                font=dict(size=14)  # Texto m√°s grande
            )
            
            # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
            # Color de los t√≠tulos:
            fig.update_annotations(font_color='white')

            # Actualizar ejes
            fig.update_yaxes(title_text="Ataques", row=1, col=1, title_font=dict(size=16), range=[0, 12])  # Ajustado m√°ximo a 12
            fig.update_yaxes(title_text="Componentes", row=2, col=1, title_font=dict(size=16))
            fig.update_xaxes(title_text="Fecha", row=2, col=1, title_font=dict(size=16))
            return fig
            
        except ImportError:
            logger.warning("Para usar gr√°ficos interactivos, instala: pip install plotly")
            return None
            
    except Exception as e:
        logger.error(f"Error al crear visualizaci√≥n de predicci√≥n: {str(e)}")
        logger.error(traceback.format_exc())
        return None

def plot_evaluation_results(_self=None):
    """
    Genera una visualizaci√≥n de los resultados de evaluaci√≥n del modelo.
    Utiliza los datos almacenados en st.session_state de una evaluaci√≥n previa.
    
    Returns:
    --------
    None
    """
    try:
        # Verificar si hay datos de evaluaci√≥n disponibles
        if 'evaluation_details' not in st.session_state or not st.session_state.evaluation_details:
            st.warning("No hay resultados de evaluaci√≥n disponibles. Por favor, ejecute primero la evaluaci√≥n del modelo.")
            return None
            
        # Verificar si tenemos los datos de validaci√≥n y predicci√≥n guardados
        if ('valid_df' not in st.session_state or 
            'forecast_valid' not in st.session_state or 
            st.session_state.valid_df is None or 
            st.session_state.forecast_valid is None):
            
            st.warning("No se encontraron datos detallados de la evaluaci√≥n. Se mostrar√° solo un resumen.")
            
            # Mostrar un resumen de m√©tricas si hay evaluation_details
            if st.session_state.evaluation_details and len(st.session_state.evaluation_details) > 0:
                details = st.session_state.evaluation_details[0]
                
                st.subheader("Resumen de Evaluaci√≥n")
                
                metric_cols = st.columns(3)
                with metric_cols[0]:
                    st.metric("RMSE", f"{details.get('rmse', 'N/A')}")
                with metric_cols[1]:
                    st.metric("MAE", f"{details.get('mae', 'N/A')}")
                with metric_cols[2]:
                    st.metric("SMAPE", f"{details.get('smape', 'N/A'):.2f}%" if 'smape' in details else 'N/A')
            else:
                st.error("No hay informaci√≥n de evaluaci√≥n disponible.")
                
            return None
            
        # Obtener los datos
        valid_df = st.session_state.valid_df
        forecast_valid = st.session_state.forecast_valid
        
        # Verificar que los DataFrames tienen datos
        if len(valid_df) == 0 or len(forecast_valid) == 0:
            st.error("Los datos de evaluaci√≥n est√°n vac√≠os. Por favor, ejecute nuevamente la evaluaci√≥n.")
            return None
            
        # Verificar que los DataFrames tienen las columnas necesarias
        required_cols_valid = ['ds', 'y']
        required_cols_forecast = ['ds', 'yhat', 'yhat_lower', 'yhat_upper']
        
        if not all(col in valid_df.columns for col in required_cols_valid):
            st.error(f"El DataFrame de validaci√≥n no contiene todas las columnas necesarias: {required_cols_valid}")
            st.info(f"Columnas disponibles: {valid_df.columns.tolist()}")
            return None
            
        if not all(col in forecast_valid.columns for col in required_cols_forecast):
            st.error(f"El DataFrame de predicci√≥n no contiene todas las columnas necesarias: {required_cols_forecast}")
            st.info(f"Columnas disponibles: {forecast_valid.columns.tolist()}")
            return None
            
        # Asegurarse de que tenemos details
        if not st.session_state.evaluation_details or len(st.session_state.evaluation_details) == 0:
            st.error("No hay detalles de evaluaci√≥n disponibles.")
            return None
            
        details = st.session_state.evaluation_details[0]
        
        # Extraer las m√©tricas
        rmse = details.get('rmse', 0)
        mae = details.get('mae', 0)
        smape = details.get('smape', 0)
        coverage = details.get('coverage', 0)
        interval_width_avg = details.get('interval_width_avg', 0)
        
        # Definir paleta de colores para tema oscuro
        colors = {
            'background': 'rgba(0,0,0,0)',      # Transparente
            'grid': 'rgba(80, 80, 80, 0.2)',    # Gris oscuro para grid
            'text': '#E0E0E0',                  # Texto claro
            'prediction': '#FF9500',            # Naranja brillante
            'interval': 'rgba(255, 149, 0, 0.15)',  # Naranja transparente
            'actual': '#2C82FF',                # Azul brillante
            'train': '#888888',                 # Gris medio
            'cutoff': 'rgba(120, 120, 120, 0.5)'  # L√≠nea de corte
        }
        
        # Crear gr√°fico para visualizar predicciones, valores reales e intervalos
        fig = go.Figure()
        
        # Obtener los datos de entrenamiento si est√°n disponibles
        train_df = None
        if 'train_df' in st.session_state:
            train_df = st.session_state.train_df
        elif 'df_prophet' in st.session_state:
            # Reconstruir aproximadamente los datos de entrenamiento
            cutoff_date = pd.to_datetime(details.get('cutoff', None))
            if cutoff_date is not None:
                train_df = st.session_state.df_prophet[st.session_state.df_prophet['ds'] <= cutoff_date].copy()
        
        # A√±adir datos de entrenamiento (√∫ltimos puntos) para dar contexto
        if train_df is not None:
            try:
                train_points = 30  # Mostrar los √∫ltimos 30 puntos de entrenamiento
                if len(train_df) > train_points:
                    context_df = train_df.iloc[-train_points:]
                else:
                    context_df = train_df
                    
                fig.add_trace(
                    go.Scatter(
                        x=context_df['ds'], y=context_df['y'],
                        mode='lines', name='Entrenamiento', line=dict(width=2)
                    )
                )
            except Exception as e:
                st.warning(f"No se pudieron agregar datos de entrenamiento al gr√°fico: {str(e)}")
        
        # A√±adir √°rea para el intervalo de predicci√≥n con estilo mejorado
        fig.add_trace(
            go.Scatter(
                x=forecast_valid['ds'], y=forecast_valid['yhat_upper'],
                fill=None, mode='lines', line=dict(width=0),
                showlegend=False, hoverinfo='skip'
            )
        )
        
        fig.add_trace(
            go.Scatter(
                x=forecast_valid['ds'], y=forecast_valid['yhat_lower'],
                fill='tonexty', mode='lines', line=dict(width=0),
                fillcolor=colors['interval'], name='Intervalo de predicci√≥n',
                showlegend=True,
                hovertemplate='<b>%{x|%d %b %y}</b><br>Rango: [%{y:.2f}, %{text:.2f}]<extra>Intervalo</extra>',
                text=forecast_valid['yhat_upper']
            )
        )
        
        # A√±adir l√≠nea de predicci√≥n con estilo mejorado
        fig.add_trace(
            go.Scatter(
                x=forecast_valid['ds'], y=forecast_valid['yhat'],
                mode='lines', name='Predicci√≥n', line=dict(color=colors['prediction'], width=3),
                hovertemplate='<b>%{x|%d %b %y}</b><br>Predicci√≥n: %{y:.2f}<extra>Predicci√≥n</extra>'
            )
        )
        
        # A√±adir puntos para valores reales con estilo mejorado
        fig.add_trace(
            go.Scatter(
                x=valid_df['ds'], y=valid_df['y'],
                mode='markers', marker=dict(
                    color=colors['actual'],
                    size=8,
                    line=dict(width=1, color='rgba(0,0,0,0.5)')
                ),
                name='Valor Real',
                hovertemplate='<b>%{x|%d %b %y}</b><br>Real: %{y:.2f}<extra>Real</extra>'
            )
        )
        
        # A√±adir anotaci√≥n para el punto de corte si est√° disponible
        if 'cutoff' in details:
            cutoff_date = pd.to_datetime(details['cutoff'])
            fig.add_shape(
                type="line",
                x0=cutoff_date,
                y0=0,
                x1=cutoff_date,
                y1=1,
                yref="paper",
                line=dict(
                    color=colors['cutoff'],
                    width=2,
                    dash="dash",
                )
            )
            
            # A√±adir texto para el punto de corte
            fig.add_annotation(
                x=cutoff_date,
                y=1.02,
                yref="paper",
                text="Punto de corte",
                showarrow=False,
                font=dict(color=colors['text'], size=12)
            )
        
        # Configurar el dise√±o del gr√°fico para tema oscuro
        fig.update_layout(
            title="Evaluaci√≥n de la Predicci√≥n",
            xaxis_title="Fecha",
            yaxis_title="Valor",
            hovermode="x unified",
            plot_bgcolor=colors['background'],
            paper_bgcolor=colors['background'],
            font=dict(color=colors['text']),
            margin=dict(l=10, r=10, t=80, b=10),
            height=500,
            
            # Agregar marca de agua tipo hacker (opcional)
            annotations=[
                dict(
                    x=0.5,
                    y=0.5,
                    xref="paper",
                    yref="paper",
                    text="CONFIDENCIAL",
                    showarrow=False,
                    font=dict(
                        family="Courier New, monospace",
                        size=60,
                        color="rgba(255, 255, 255, 0.03)"
                    ),
                    textangle=25,
                    opacity=0.7
                )
            ]
        )
        
        # Mejorar la apariencia de los ejes
        fig.update_xaxes(
            showgrid=True,
            gridcolor=colors['grid'],
            zeroline=False,
            tickangle=-45,
            title_font=dict(color=colors['text']),
            tickfont=dict(color=colors['text'])
        )
        
        fig.update_yaxes(
            showgrid=True,
            gridcolor=colors['grid'],
            zeroline=True,
            zerolinecolor=colors['grid'],
            title_font=dict(color=colors['text']),
            tickfont=dict(color=colors['text'])
        )
        
        # Mostrar el gr√°fico
        st.plotly_chart(fig, use_container_width=True)
        
        # Gu√≠a de interpretaci√≥n del gr√°fico con mejor estilo
        st.markdown("""
        <div style="background-color: rgba(40, 40, 40, 0.7); padding: 15px; border-radius: 5px; margin-bottom: 20px;">
            <h4 style="margin-top: 0;">Gu√≠a de interpretaci√≥n</h4>
            <ul>
                <li><span style="color: #FF9500; font-weight: bold;">L√≠nea naranja:</span> Representa la predicci√≥n del modelo para cada fecha.</li>
                <li><span style="color: #2C82FF; font-weight: bold;">Puntos azules:</span> Muestran los valores reales observados.</li>
                <li><span style="color: #FF9500; opacity: 0.5;">√Årea sombreada:</span> Indica el intervalo de predicci√≥n (donde se espera que est√©n los valores reales).</li>
                <li><span style="color: #888888;">L√≠nea punteada gris:</span> Muestra los √∫ltimos datos de entrenamiento para dar contexto.</li>
            </ul>
            <h4>¬øQu√© buscar?</h4>
            <ul>
                <li><strong>Precisi√≥n general:</strong> Cuanto m√°s cerca est√©n los puntos azules de la l√≠nea naranja, mejor es la predicci√≥n.</li>
                <li><strong>Cobertura:</strong> Idealmente, todos los puntos azules deber√≠an estar dentro del √°rea sombreada.</li>
                <li><strong>Amplitud:</strong> Un √°rea sombreada muy amplia indica mayor incertidumbre en las predicciones.</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
        
        # Mostrar m√©tricas en tarjetas con columnas para mejor visualizaci√≥n
        st.subheader("M√©tricas de Evaluaci√≥n")
        metric_cols = st.columns(4)
        
        with metric_cols[0]:
            st.metric("RMSE", f"{rmse:.2f}")
            
        with metric_cols[1]:
            st.metric("MAE", f"{mae:.2f}")
            
        with metric_cols[2]:
            st.metric("SMAPE", f"{smape:.1f}%")
            
        with metric_cols[3]:
            st.metric("Cobertura", f"{coverage:.1f}%")
        
        # An√°lisis de cobertura
        if coverage < 80:
            st.warning("‚ö†Ô∏è La cobertura del intervalo de predicci√≥n es baja. Considere aumentar el ancho del intervalo.")
        elif coverage > 95:
            st.info("‚ÑπÔ∏è La cobertura del intervalo es muy alta. Podr√≠a reducir el ancho del intervalo para predicciones m√°s precisas.")
        else:
            st.success("‚úÖ La cobertura del intervalo de predicci√≥n es adecuada.")
            
        # An√°lisis de errores
        error_df = pd.DataFrame({
            'Fecha': valid_df['ds'],
            'Real': valid_df['y'].values,  # Use .values to convert to numpy array
            'Predicci√≥n': forecast_valid['yhat'].values,  # Use .values to convert to numpy array
            'Error': valid_df['y'].values - forecast_valid['yhat'].values,
            'Error (%)': np.abs((valid_df['y'].values - forecast_valid['yhat'].values) / (valid_df['y'].values + 1e-8)) * 100,
            'Dentro del Intervalo': (valid_df['y'].values >= forecast_valid['yhat_lower'].values) & 
                                   (valid_df['y'].values <= forecast_valid['yhat_upper'].values)
        })
        
        # Mostrar tabla de errores con formato mejorado
        st.subheader("An√°lisis Detallado de Errores")
        st.dataframe(
            error_df.style.format({
                'Real': '{:.2f}',
                'Predicci√≥n': '{:.2f}',
                'Error': '{:.2f}',
                'Error (%)': '{:.1f}%',
                'Dentro del Intervalo': lambda x: '‚úÖ' if x else '‚ùå'
            }).applymap(
                lambda x: 'background-color: rgba(255, 149, 0, 0.1)' if isinstance(x, bool) and not x else None,
                subset=['Dentro del Intervalo']
            ),
            use_container_width=True
        )
        
        st.success("‚úÖ Evaluaci√≥n completada con √©xito.")
        return fig
        
    except Exception as e:
        st.error(f"Error al visualizar resultados de evaluaci√≥n: {str(e)}")
        import traceback
        st.code(traceback.format_exc())
        return None

def _log_data_flow(action, source, df=None, details=None):
    """
    Registra informaci√≥n sobre el flujo de datos para diagn√≥stico.
    
    Parameters:
    -----------
    action : str
        Acci√≥n que se est√° realizando (e.g., 'load', 'prepare', 'train', 'evaluate')
    source : str
        Fuente de los datos
    df : pandas.DataFrame, optional
        DataFrame que se est√° procesando
    details : dict, optional
        Detalles adicionales para registrar
    """
    if 'data_flow_log' not in st.session_state:
        st.session_state.data_flow_log = []
    
    log_entry = {
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'action': action,
        'source': source,
    }
    
    if df is not None:
        log_entry['shape'] = df.shape
        log_entry['columns'] = df.columns.tolist()
        log_entry['has_nulls'] = df.isnull().any().any()
        
        # Verificar columnas cr√≠ticas
        if 'ds' in df.columns:
            log_entry['ds_min'] = df['ds'].min().strftime('%Y-%m-%d') if not pd.isna(df['ds'].min()) else None
            log_entry['ds_max'] = df['ds'].max().strftime('%Y-%m-%d') if not pd.isna(df['ds'].max()) else None
        
        if 'y' in df.columns:
            log_entry['y_min'] = float(df['y'].min()) if not pd.isna(df['y'].min()) else None
            log_entry['y_max'] = float(df['y'].max()) if not pd.isna(df['y'].max()) else None
            log_entry['y_mean'] = float(df['y'].mean()) if not pd.isna(df['y'].mean()) else None
    
    if details:
        log_entry.update(details)
    
    st.session_state.data_flow_log.append(log_entry)
    logger.info(f"Data flow: {action} from {source}" + 
               (f" shape={df.shape}" if df is not None else ""))

def _show_prediction_summary(forecast, model, use_log_transform, optimizations_applied=None):
    """
    Muestra un resumen de la predicci√≥n generada.
    
    Parameters:
    -----------
    forecast : pandas.DataFrame
        DataFrame con las predicciones generadas
    model : Prophet
        Modelo utilizado para generar las predicciones
    use_log_transform : bool
        Indica si se aplic√≥ transformaci√≥n logar√≠tmica a los datos
    optimizations_applied : dict, optional
        Optimizaciones aplicadas al modelo
    """
    try:
        # Verificar que el forecast tenga datos
        if forecast is None or len(forecast) == 0:
            st.warning("No hay datos de predicci√≥n para mostrar")
            return
            
        # Extraer estad√≠sticas clave de la predicci√≥n
        stats = {
            'total_rows': len(forecast),
            'future_rows': len(forecast[forecast['ds'] > pd.Timestamp.now()]),
            'start_date': forecast['ds'].min().strftime('%Y-%m-%d'),
            'end_date': forecast['ds'].max().strftime('%Y-%m-%d'),
            'min_value': forecast['yhat'].min(),
            'max_value': forecast['yhat'].max(),
            'mean_value': forecast['yhat'].mean(),
            'trend_direction': 'ascendente' if forecast['yhat'].iloc[-1] > forecast['yhat'].iloc[0] else 'descendente'
        }
        
        # Mostrar resumen en formato de tarjetas
        st.markdown("### üìä Resumen de la Predicci√≥n")
        
        # Fechas y tama√±o de la predicci√≥n
        date_cols = st.columns(3)
        with date_cols[0]:
            st.metric("Per√≠odo Predicho", f"{stats['start_date']} a {stats['end_date']}")
        with date_cols[1]:
            st.metric("D√≠as Totales", stats['total_rows'])
        with date_cols[2]:
            st.metric("D√≠as Futuros", stats['future_rows'])
        
        # Valores clave de la predicci√≥n
        value_cols = st.columns(4)
        with value_cols[0]:
            value_label = "Valor M√≠nimo"
            if use_log_transform:
                value_label += " (log)"
            st.metric(value_label, f"{stats['min_value']:.2f}")
            
        with value_cols[1]:
            value_label = "Valor M√°ximo"
            if use_log_transform:
                value_label += " (log)"
            st.metric(value_label, f"{stats['max_value']:.2f}")
            
        with value_cols[2]:
            value_label = "Valor Promedio"
            if use_log_transform:
                value_label += " (log)"
            st.metric(value_label, f"{stats['mean_value']:.2f}")
            
        with value_cols[3]:
            st.metric("Tendencia General", stats['trend_direction'], 
                    delta="‚ñ≤" if stats['trend_direction'] == 'ascendente' else "‚ñº",
                    delta_color="normal" if stats['trend_direction'] == 'ascendente' else "inverse")
        
        # Mostrar informaci√≥n sobre optimizaciones si est√°n disponibles
        if optimizations_applied and isinstance(optimizations_applied, dict) and len(optimizations_applied) > 0:
            st.markdown("#### Optimizaciones Aplicadas")
            for opt_name, opt_value in optimizations_applied.items():
                st.info(f"**{opt_name}**: {opt_value}")
                
        # Mostrar nota sobre transformaci√≥n logar√≠tmica si se aplic√≥
        if use_log_transform:
            st.info("‚ÑπÔ∏è Se aplic√≥ transformaci√≥n logar√≠tmica a los datos. Los valores de predicci√≥n est√°n en escala logar√≠tmica.")
    
    except Exception as e:
        st.warning(f"No se pudo mostrar el resumen de la predicci√≥n: {str(e)}")
        import traceback
        logger.error(f"Error en _show_prediction_summary: {traceback.format_exc()}")


def _display_evaluation_results(
    metrics: Dict[str, Any],
    all_metrics: Optional[List[Dict[str, Any]]],
    df: pd.DataFrame,
    test_predictions: pd.DataFrame,
    multi_eval: bool = False,
    use_log_transform: bool = False
) -> Optional[Dict[str, float]]:
    """
    Muestra los resultados de la evaluaci√≥n del modelo.

    Parameters:
    -----------
    metrics : dict
        Diccionario con m√©tricas calculadas
    all_metrics : list
        Lista de m√©tricas para m√∫ltiples puntos de corte
    df : pandas.DataFrame
        DataFrame con los datos completos
    test_predictions : pandas.DataFrame
        DataFrame con predicciones de prueba (columnas: ds, yhat, yhat_lower, yhat_upper)
    multi_eval : bool
        Indica si se realiz√≥ evaluaci√≥n con m√∫ltiples puntos de corte
    use_log_transform : bool
        Indica si se aplic√≥ transformaci√≥n logar√≠tmica a los datos
    
    Returns:
    --------
    dict
        Diccionario con las m√©tricas de evaluaci√≥n o None en caso de error
    """
    # Mostrar estado de evaluaci√≥n
    st.success("‚úÖ Evaluaci√≥n del modelo completada")
    st.markdown("### M√©tricas de Rendimiento")

    # Mostrar m√©tricas clave en tarjetas
    cols = st.columns(4)
    with cols[0]:
        st.metric(
            label="Amplitud Promedio",
            value=f"{metrics.get('interval_width_avg', 0):.2f}",
            help="Promedio de la amplitud de los intervalos de predicci√≥n. Valores m√°s bajos indican mayor precisi√≥n."
        )
    with cols[1]:
        coverage = metrics.get('coverage', 0)
        color = '#4CAF50' if 80 <= coverage <= 95 else '#FF9800'
        st.metric(
            label="Cobertura Intervalos (%)",
            value=f"{coverage:.1f}%",
            delta_color="normal",
            help="% de valores reales dentro del intervalo de predicci√≥n. Deber√≠a ser cercano al nivel de confianza."
        )
    with cols[2]:
        st.metric(
            label="Error (SMAPE)",
            value=f"{metrics.get('smape', 0):.1f}%",
            help="Error porcentual medio sim√©trico. Valores m√°s bajos indican mejor precisi√≥n."
        )
    with cols[3]:
        st.metric(
            label="Iteraciones",
            value=metrics.get('iterations', 1),
            help="Cantidad de iteraciones realizadas."
        )

    # Tabla de m√©tricas por punto de corte
    if multi_eval and all_metrics:
        st.markdown("#### M√©tricas por Punto de Corte")
        df_met = pd.DataFrame(all_metrics)
        if 'cutoff' in df_met.columns:
            df_met = df_met.sort_values('cutoff')
        st.dataframe(df_met)

    # Visualizaci√≥n de backtesting
    st.markdown("### Visualizaci√≥n de Backtesting")
    try:
        if test_predictions is not None and not test_predictions.empty:
            # Definir rangos de datos
            start_date = test_predictions['ds'].min()
            
            if pd.isna(start_date):
                st.warning("Fecha m√≠nima de predicciones inv√°lida.")
                return metrics

            # Datos de entrenamiento y validaci√≥n
            train = df[df['ds'] < start_date]
            valid = df[df['ds'].isin(test_predictions['ds'])]

            fig = go.Figure()
            if not train.empty:
                fig.add_trace(go.Scatter(
                    x=train['ds'], y=train['y'],
                    mode='lines', name='Entrenamiento', line=dict(width=2)
                ))
            if not valid.empty:
                fig.add_trace(go.Scatter(
                    x=valid['ds'], y=valid['y'],
                    mode='lines', name='Valores Reales', line=dict(width=2)
                ))
            # Predicci√≥n
            fig.add_trace(go.Scatter(
                x=test_predictions['ds'], y=test_predictions['yhat'],
                mode='lines', name='Predicci√≥n', line=dict(width=2)
            ))
            # Intervalo de confianza
            fig.add_trace(go.Scatter(
                x=pd.concat([test_predictions['ds'], test_predictions['ds'][::-1]]),
                y=pd.concat([test_predictions['yhat_upper'], test_predictions['yhat_lower'][::-1]]),
                fill='toself', name='Intervalo 95%', fillcolor='rgba(255,0,0,0.2)', line=dict(width=0)
            ))

            # Configurar layout
            fig.update_layout(
                title='Backtesting: Predicci√≥n vs Real',
                xaxis_title='Fecha', yaxis_title='Valor',
                hovermode='x unified', template='plotly_white'
            )

            # A√±adir anotaciones explicativas
            if len(valid) > 3:
                try:
                    # Encontrar punto con mayor error para anotaci√≥n
                    errors = np.abs(test_predictions['yhat'].values - valid['y'].values)
                    max_error_idx = np.argmax(errors)
                    
                    if max_error_idx < len(valid):
                        max_error_date = valid.iloc[max_error_idx]['ds']
                        max_error_pred = test_predictions.iloc[max_error_idx]['yhat']
                        max_error_real = valid.iloc[max_error_idx]['y']
                        
                        fig.add_annotation(
                            x=max_error_date,
                            y=max_error_real,
                            text="Mayor error",
                            showarrow=True,
                            arrowhead=2,
                            arrowsize=1,
                            arrowwidth=2,
                            arrowcolor='#616161',
                            ax=-40,
                            ay=-40,
                            font=dict(size=12, color='#616161'),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor='#616161',
                            borderwidth=1,
                            borderpad=4
                        )
                    
                    # Encontrar punto con predicci√≥n m√°s alta
                    max_pred_idx = np.argmax(test_predictions['yhat'].values)
                    max_pred_date = test_predictions.iloc[max_pred_idx]['ds']
                    max_pred_value = test_predictions.iloc[max_pred_idx]['yhat']
                    
                    fig.add_annotation(
                        x=max_pred_date,
                        y=max_pred_value,
                        text="Pico predicho",
                        showarrow=True,
                        arrowhead=2,
                        arrowsize=1,
                        arrowwidth=2,
                        arrowcolor='rgb(0,100,80)',
                        ax=40,
                        ay=-40,
                        font=dict(size=12, color='rgb(0,100,80)'),
                        bgcolor="rgba(255,255,255,0.8)",
                        bordercolor='rgb(0,100,80)',
                        borderwidth=1,
                        borderpad=4
                    )
                    
                    # A√±adir l√≠nea para valor medio predicho
                    avg_pred = np.mean(test_predictions['yhat'].values)
                    fig.add_shape(
                        type="line",
                        x0=test_predictions['ds'].min(),
                        y0=avg_pred,
                        x1=test_predictions['ds'].max(),
                        y1=avg_pred,
                        line=dict(
                            color="rgba(33, 150, 243, 0.5)",
                            width=1,
                            dash="dot",
                        )
                    )
                    
                    fig.add_annotation(
                        x=test_predictions['ds'].max(),
                        y=avg_pred,
                        text=f"Media: {avg_pred:.2f}",
                        showarrow=False,
                        xanchor="right",
                        font=dict(size=10, color='rgb(0,100,80)'),
                        bgcolor="rgba(255,255,255,0.8)",
                        bordercolor='rgb(0,100,80)',
                        borderwidth=1,
                        borderpad=2
                    )
                except Exception as e:
                    st.warning(f"No se pudieron a√±adir anotaciones al gr√°fico: {str(e)}")

            st.plotly_chart(fig, use_container_width=True)
            
            # A√±adir resumen interpretativo
            with st.expander("üìä C√≥mo interpretar este gr√°fico", expanded=True):
                st.markdown("""
                <div style="background-color: rgba(40, 40, 40, 0.7); padding: 15px; border-radius: 5px; margin-bottom: 20px;">
                    <h4 style="margin-top: 0;">Gu√≠a de interpretaci√≥n</h4>
                    <ul>
                        <li><span style="color: #FF9500; font-weight: bold;">L√≠nea naranja:</span> Representa la predicci√≥n del modelo para cada fecha.</li>
                        <li><span style="color: #2C82FF; font-weight: bold;">Puntos azules:</span> Muestran los valores reales observados.</li>
                        <li><span style="color: #FF9500; opacity: 0.5;">√Årea sombreada:</span> Indica el intervalo de predicci√≥n (donde se espera que est√©n los valores reales).</li>
                        <li><span style="color: #888888;">L√≠nea punteada gris:</span> Muestra los √∫ltimos datos de entrenamiento para dar contexto.</li>
                    </ul>
                    <h4>¬øQu√© buscar?</h4>
                    <ul>
                        <li><strong>Precisi√≥n general:</strong> Cuanto m√°s cerca est√©n los puntos azules de la l√≠nea naranja, mejor es la predicci√≥n.</li>
                        <li><strong>Cobertura:</strong> Idealmente, todos los puntos azules deber√≠an estar dentro del √°rea sombreada.</li>
                        <li><strong>Amplitud:</strong> Un √°rea sombreada muy amplia indica mayor incertidumbre en las predicciones.</li>
                    </ul>
                </div>
                """, unsafe_allow_html=True)
    except Exception as exc:
        st.error(f"Error al generar la visualizaci√≥n de backtesting: {exc}")
        return None

    return metrics

def _prepare_training_dataframe(df=None):
    """
    Prepara y verifica el DataFrame para entrenamiento.
    
    Args:
        df: DataFrame opcional con datos de entrenamiento
        
    Returns:
        DataFrame preparado para entrenamiento o None si no hay datos
    """
    logger.info("Preparando DataFrame para entrenamiento")
    
    # Si no se proporciona df, intentar obtenerlo de la sesi√≥n de Streamlit
    if df is None:
        logger.info("No se proporcion√≥ DataFrame, intentando obtenerlo de la sesi√≥n")
        if 'df_prophet' in st.session_state:
            df = st.session_state.df_prophet
            logger.info(f"DataFrame obtenido de sesi√≥n: {len(df)} filas")
        else:
            st.error("No hay datos para entrenar. Por favor, cargue datos primero.")
            return None
    
    # Verificar si hay datos suficientes
    if df is None or len(df) < 10:
        st.error("Datos insuficientes para entrenar modelo")
        return None
        
    # Verificar columnas m√≠nimas requeridas
    required_cols = ['ds', 'y']
    if not all(col in df.columns for col in required_cols):
        missing = [col for col in required_cols if col not in df.columns]
        st.error(f"El DataFrame no contiene las columnas requeridas: {missing}")
        return None
    
    # A√±adir caracter√≠sticas avanzadas de ciberseguridad
    try:
        from .feature_engineering import FeatureEngineer
        
        logger.info("Generando caracter√≠sticas avanzadas para ciberseguridad")
        
        # Crear una copia para no modificar el original
        df_enhanced = df.copy()
        
        # A√±adir caracter√≠sticas temporales b√°sicas si no existen
        if not any(col.startswith('month_') for col in df.columns):
            logger.info("A√±adiendo caracter√≠sticas temporales b√°sicas")
            df_enhanced = FeatureEngineer.add_temporal_features(df_enhanced)
        
        # A√±adir caracter√≠sticas espec√≠ficas para ciberseguridad
        if not any(col in df.columns for col in ['is_patch_tuesday', 'days_since_patch_tuesday']):
            logger.info("A√±adiendo caracter√≠sticas espec√≠ficas para ciberseguridad")
            df_enhanced = FeatureEngineer.add_cybersecurity_features(df_enhanced)
            
            # Informar sobre las nuevas caracter√≠sticas
            new_features = [col for col in df_enhanced.columns if col not in df.columns]
            logger.info(f"Caracter√≠sticas de ciberseguridad a√±adidas: {new_features}")
            
            if len(new_features) > 0:
                st.success(f"‚úÖ Se a√±adieron {len(new_features)} caracter√≠sticas avanzadas para mejorar la predicci√≥n de ransomware")
        
        # Intentar a√±adir datos de CVE si est√°n disponibles
        try:
            cve_path = os.path.join('modeling', 'cve_diarias_regresor_prophet.csv')
            if os.path.exists(cve_path) and not any(col.startswith('cve_') for col in df_enhanced.columns):
                logger.info(f"Intentando cargar datos de CVE desde {cve_path}")
                
                # Cargar datos de CVE
                cve_df = pd.read_csv(cve_path)
                
                # Asegurarse de que la columna de fecha est√© en formato datetime
                if 'ds' in cve_df.columns:
                    cve_df['ds'] = pd.to_datetime(cve_df['ds'])
                    
                    # Fusionar con el DataFrame principal
                    df_enhanced = pd.merge(df_enhanced, cve_df, on='ds', how='left')
                    
                    # Rellenar valores faltantes
                    cve_cols = [col for col in cve_df.columns if col != 'ds']
                    for col in cve_cols:
                        if col in df_enhanced.columns and df_enhanced[col].isna().any():
                            df_enhanced[col].fillna(df_enhanced[col].median(), inplace=True)
                    
                    logger.info(f"Datos de CVE integrados: {len(cve_cols)} variables")
                    st.success(f"‚úÖ Datos de vulnerabilidades (CVE) incorporados como regresores")
        except Exception as e:
            logger.warning(f"No se pudieron cargar datos de CVE: {str(e)}")
            
        return df_enhanced
        
    except Exception as e:
        logger.error(f"Error al generar caracter√≠sticas avanzadas: {str(e)}")
        # Devolver el DataFrame original si hay problemas con las caracter√≠sticas avanzadas
        st.warning(f"‚ö†Ô∏è No se pudieron generar todas las caracter√≠sticas avanzadas: {str(e)}")
        return df

def _setup_model_config(
    seasonality_mode, use_log_transform, changepoint_prior_scale, 
    seasonality_prior_scale, holidays_prior_scale, regressors_prior_scale,
    interval_width, changepoint_range, n_changepoints, use_detected_changepoints,
    daily_seasonality, weekly_seasonality, yearly_seasonality
):
    """
    Configura los par√°metros del modelo Prophet.
    
    Returns:
        Diccionario con la configuraci√≥n del modelo
    """
    return {
        'seasonality_mode': seasonality_mode,
        'use_log_transform': use_log_transform,
        'changepoint_prior_scale': changepoint_prior_scale,
        'seasonality_prior_scale': seasonality_prior_scale,
        'holidays_prior_scale': holidays_prior_scale,
        'regressors_prior_scale': regressors_prior_scale,
        'interval_width': interval_width,
        'changepoint_range': changepoint_range,
        'n_changepoints': n_changepoints,
        'use_detected_changepoints': use_detected_changepoints,
        'daily_seasonality': daily_seasonality,
        'weekly_seasonality': weekly_seasonality,
        'yearly_seasonality': yearly_seasonality
    }

def _prepare_regressors(use_regressor, correlation_threshold, vif_threshold):
    """
    Prepara los regresores para el modelo si se solicitan.
    
    Args:
        use_regressor: Si se deben usar regresores
        correlation_threshold: Umbral de correlaci√≥n para selecci√≥n
        vif_threshold: Umbral de VIF para multicolinealidad
        
    Returns:
        Objeto RegressorGenerator configurado o None
    """
    if not use_regressor:
        return None
        
    try:
        from .features.regressors import RegressorGenerator
        logger.info("Configurando regresores")
        
        # Inicializar generador de regresores
        if 'regressors' not in st.session_state or st.session_state.regressors is None:
            st.session_state.regressors = RegressorGenerator()
            
        regressors = st.session_state.regressors
        
        # Cargar datos de CVE mediante el dataframe si est√° disponible en la sesi√≥n
        cve_df = None
        cve_file = 'modeling/cve_diarias_regresor_prophet.csv'
        
        if hasattr(st.session_state, 'cve_file') and st.session_state.cve_file:
            cve_file = st.session_state.cve_file
        
        # Intentar obtener df_cve del forecaster si existe
        if 'forecaster' in st.session_state and hasattr(st.session_state.forecaster, 'df_cve'):
            cve_df = st.session_state.forecaster.df_cve
        else:
            # Cargar datos CVE manualmente
            try:
                cve_df = pd.read_csv(cve_file)
                if 'fecha' in cve_df.columns:
                    cve_df = cve_df.rename(columns={'fecha': 'ds'})
                # Convertir a datetime
                cve_df['ds'] = pd.to_datetime(cve_df['ds'])
            except Exception as e:
                logger.warning(f"No se pudieron cargar datos de CVE: {str(e)}")
                
        # Configurar par√°metros de selecci√≥n de regresores
        regressors.correlation_threshold = correlation_threshold
        regressors.vif_threshold = vif_threshold
        
        return regressors
    except Exception as e:
        logger.error(f"Error preparando regresores: {str(e)}")
        st.warning(f"No se pudieron preparar los regresores: {str(e)}")
        return None

def _train_prophet_model(df, model_config, regressors, use_optimal_regressors=True, use_interval_calibration=True):
    """
    Entrena el modelo Prophet con los par√°metros y regresores proporcionados.
    
    Args:
        df: DataFrame con datos de entrenamiento
        model_config: Configuraci√≥n del modelo
        regressors: Objeto RegressorGenerator configurado
        use_optimal_regressors: Si usar selecci√≥n autom√°tica de regresores
        use_interval_calibration: Si calibrar intervalos de predicci√≥n
        
    Returns:
        Modelo entrenado o None en caso de error
    """
    from .models.prophet_model import RansomwareProphetModel
    
    try:
        # Crear instancia del modelo
        model = RansomwareProphetModel()
        
        # Establecer par√°metros
        for param, value in model_config.items():
            setattr(model, param, value)
        
        # Entrenar modelo
        st.info("Entrenando modelo Prophet...")
        
        # Si hay regresores disponibles, prepararlos
        regressor_df = None
        if regressors is not None and use_optimal_regressors:
            try:
                # Preparar regresores basados en datos CVE
                if hasattr(st.session_state.forecaster, 'df_cve'):
                    cve_df = st.session_state.forecaster.df_cve
                    if cve_df is not None and len(cve_df) > 0:
                        regressor_df = regressors.prepare_regressors(df, cve_df)
                        st.info(f"Preparados {len(regressor_df.columns) - 1} regresores potenciales")
            except Exception as e:
                st.warning(f"Error preparando regresores: {str(e)}")
        
        # Entrenar el modelo
        model.fit(df, regressors=regressor_df)
        
        # Calibrar intervalos si se solicita
        if use_interval_calibration:
            try:
                from .models.calibrator import IntervalCalibrator
                calibrator = IntervalCalibrator()
                st.info("Calibrando intervalos de predicci√≥n...")
                # Implementar calibraci√≥n
            except Exception as e:
                st.warning(f"No se pudieron calibrar intervalos: {str(e)}")
        
        # Guardar en sesi√≥n
        st.session_state.prophet_model = model
        st.session_state.model_trained = True
        
        st.success("‚úÖ Modelo entrenado correctamente")
        return model
        
    except Exception as e:
        st.error(f"Error entrenando modelo: {str(e)}")
        logger.error(f"Error entrenando modelo: {traceback.format_exc()}")
        return None

def train_model_wrapper(
    df: Optional[pd.DataFrame] = None,
    use_regressor: bool = True,
    use_optimal_regressors: bool = True,
    use_bayesian_optimization: bool = False,
    use_interval_calibration: bool = True,
    optimization_trials: int = 10,
    correlation_threshold: float = 0.1,
    vif_threshold: float = 5.0,
    seasonality_mode: str = 'multiplicative',
    use_log_transform: bool = True,
    changepoint_prior_scale: float = 0.05,
    seasonality_prior_scale: float = 10.0,
    holidays_prior_scale: float = 10.0,
    regressors_prior_scale: float = 0.1,
    interval_width: float = 0.6,
    changepoint_range: float = 0.8,
    n_changepoints: int = 25,
    use_detected_changepoints: bool = False,
    daily_seasonality: bool = False,
    weekly_seasonality: bool = True,
    yearly_seasonality: bool = True,
    calibrate_intervals: bool = True
) -> tuple:
    """
    Wrapper para entrenar el modelo Prophet a trav√©s de la UI de Streamlit.
    
    Esta funci√≥n coordina el proceso completo de entrenamiento del modelo, incluyendo:
    - Preparaci√≥n de datos
    - Configuraci√≥n del modelo
    - Selecci√≥n de regresores (si se solicita)
    - Entrenamiento del modelo
    - Calibraci√≥n de intervalos (si se solicita)
    
    Args:
        df: DataFrame con datos de entrenamiento (opcional, si no se proporciona se obtiene de la sesi√≥n)
        use_regressor: Si se deben usar regresores
        use_optimal_regressors: Si se deben usar regresores √≥ptimos
        use_bayesian_optimization: Si se debe usar optimizaci√≥n bayesiana
        use_interval_calibration: Si se debe calibrar los intervalos
        optimization_trials: N√∫mero de pruebas para optimizaci√≥n bayesiana
        correlation_threshold: Umbral de correlaci√≥n para selecci√≥n de regresores
        vif_threshold: Umbral de VIF para controlar multicolinealidad entre regresores
        seasonality_mode: Modo de estacionalidad ('additive' o 'multiplicative')
        use_log_transform: Si se debe aplicar transformaci√≥n logar√≠tmica
        changepoint_prior_scale: Escala previa de puntos de cambio
        seasonality_prior_scale: Escala previa de estacionalidad
        holidays_prior_scale: Escala previa de festivos
        regressors_prior_scale: Escala previa de regresores
        interval_width: Ancho del intervalo de predicci√≥n
        changepoint_range: Rango de puntos de cambio
        n_changepoints: N√∫mero de puntos de cambio
        use_detected_changepoints: Si se deben usar puntos de cambio detectados
        daily_seasonality: Si se debe usar estacionalidad diaria
        weekly_seasonality: Si se debe usar estacionalidad semanal
        yearly_seasonality: Si se debe usar estacionalidad anual
        calibrate_intervals: Si se deben calibrar los intervalos
        
    Returns:
    --------
    Tupla con (modelo entrenado, DataFrame de predicci√≥n)
    """
    # 1. Preparar y verificar DataFrame
    df = _prepare_training_dataframe(df)
    if df is None:
        return None, None
    
    # 2. Configurar par√°metros del modelo
    model_config = _setup_model_config(
        seasonality_mode, use_log_transform, changepoint_prior_scale,
        seasonality_prior_scale, holidays_prior_scale, regressors_prior_scale,
        interval_width, changepoint_range, n_changepoints, use_detected_changepoints,
        daily_seasonality, weekly_seasonality, yearly_seasonality
    )
    
    # 3. Preparar regresores si se solicitan
    regressors = _prepare_regressors(use_regressor, correlation_threshold, vif_threshold)
    
    # 4. Entrenar el modelo
    model = _train_prophet_model(
        df, model_config, regressors, 
        use_optimal_regressors, use_interval_calibration
    )
    
    # 5. Realizar una predicci√≥n inicial para comprobar que todo funciona
    forecast = None
    if model is not None:
        try:
            forecast = model.predict(periods=30, include_history=True)
            st.session_state.forecast = forecast
        except Exception as e:
            st.error(f"Error generando predicci√≥n inicial: {str(e)}")
    
    return model, forecast

def plot_forecast_wrapper():
    """
    Crea una visualizaci√≥n Plotly de la predicci√≥n almacenada en session_state.
    
    Returns:
        Figura Plotly con la visualizaci√≥n o None si hay un error
    """
    try:
        # Verificar si hay una predicci√≥n disponible
        if 'forecast' not in st.session_state:
            logger.error("No hay predicci√≥n disponible en session_state")
            return None
            
        forecast = st.session_state.forecast
        
        # Verificar que forecast no sea None
        if forecast is None:
            logger.error("La predicci√≥n en session_state es None")
            return None
            
        # Verificar que forecast sea un DataFrame
        if not isinstance(forecast, pd.DataFrame):
            logger.error(f"La predicci√≥n no es un DataFrame, es {type(forecast)}")
            return None
            
        # Verificar que forecast no est√© vac√≠o
        if forecast.empty:
            logger.error("El DataFrame de predicci√≥n est√° vac√≠o")
            return None
            
        # Imprimir las columnas disponibles para diagn√≥stico
        logger.info(f"Columnas en forecast: {list(forecast.columns)}")
        
        # Verificar que el DataFrame tenga las columnas necesarias
        required_cols = ['ds', 'yhat']
        missing_cols = [col for col in required_cols if col not in forecast.columns]
        if missing_cols:
            logger.error(f"Faltan columnas necesarias en el DataFrame de predicci√≥n: {missing_cols}")
            return None
        
        try:
            # Crear figura con subplots
            fig = make_subplots(
                rows=2, cols=1,
                shared_xaxes=True,
                vertical_spacing=0.1,
                subplot_titles=("Predicci√≥n de ataques ransomware", "Componentes")
            )
            
            # A√±adir datos hist√≥ricos
            if 'df_prophet' in st.session_state and st.session_state.df_prophet is not None:
                fig.add_trace(
                    go.Scatter(
                        x=st.session_state.df_prophet['ds'],
                        y=st.session_state.df_prophet['y'],
                        mode='markers',
                        name='Datos hist√≥ricos',
                        marker=dict(color='#FF9F1C', size=8)  # Naranja brillante
                    ),
                    row=1, col=1
                )
            
            # Predicci√≥n
            fig.add_trace(
                go.Scatter(
                    x=forecast['ds'],
                    y=forecast['yhat'],
                    mode='lines',
                    name='Predicci√≥n',
                    line=dict(color='blue', width=3)  # Aumentado ancho de l√≠nea
                ),
                row=1, col=1
            )
            
            # Marcar √°rea futura
            if 'df_prophet' in st.session_state and st.session_state.df_prophet is not None:
                future_mask = ~forecast['ds'].isin(st.session_state.df_prophet['ds'])
                if future_mask.sum() > 0:
                    fig.add_trace(
                        go.Scatter(
                            x=forecast.loc[future_mask, 'ds'],
                            y=forecast.loc[future_mask, 'yhat'],
                            mode='lines',
                            name='Predicci√≥n futura',
                            line=dict(color='red', width=4)  # Aumentado ancho de l√≠nea de 2.5 a 4
                        ),
                        row=1, col=1
                    )
            
            # A√±adir intervalos de confianza
            if 'yhat_lower' in forecast.columns and 'yhat_upper' in forecast.columns:
                fig.add_trace(
                    go.Scatter(
                        x=forecast['ds'],
                        y=forecast['yhat_upper'],
                        mode='lines',
                        name='L√≠mite superior',
                        line=dict(width=0),
                        showlegend=False
                    ),
                    row=1, col=1
                )
                
                fig.add_trace(
                    go.Scatter(
                        x=forecast['ds'],
                        y=forecast['yhat_lower'],
                        mode='lines',
                        name='Intervalo de confianza',
                        line=dict(width=0),
                        fill='tonexty',
                        fillcolor='rgba(0, 0, 255, 0.3)'  # Aumentado opacidad de 0.2 a 0.3
                    ),
                    row=1, col=1
                )
            
            # A√±adir componentes - solo tendencia
            if 'trend' in forecast.columns:
                fig.add_trace(
                    go.Scatter(
                        x=forecast['ds'],
                        y=forecast['trend'],
                        mode='lines',
                        name='Tendencia',
                        line=dict(color='green', width=3)  # Aumentado ancho de l√≠nea de 2 a 3
                    ),
                    row=2, col=1
                )
            
            # Actualizar dise√±o
            fig.update_layout(
                height=600,  # Reducido para mejor proporci√≥n
                width=1200,  # Un poco m√°s ancho
                hovermode='x unified',
                legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='center', x=0.5),
                template='plotly_white',
                font=dict(size=14)  # Texto m√°s grande
            )
            
            # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî
            # Color de los t√≠tulos:
            fig.update_annotations(font_color='white')

            # Actualizar ejes
            fig.update_yaxes(title_text="Ataques", row=1, col=1, title_font=dict(size=16), range=[0, 12])  # Ajustado m√°ximo a 12
            fig.update_yaxes(title_text="Componentes", row=2, col=1, title_font=dict(size=16))
            fig.update_xaxes(title_text="Fecha", row=2, col=1, title_font=dict(size=16))
            return fig
            
        except ImportError:
            logger.warning("Para usar gr√°ficos interactivos, instala: pip install plotly")
            return None
            
    except Exception as e:
        logger.error(f"Error al crear visualizaci√≥n de predicci√≥n: {str(e)}")
        logger.error(traceback.format_exc())
        return None

def evaluate_model_wrapper(_self=None, cv_periods=30, initial=None, period=None, horizon=None, 
                       max_iterations=3, train_percentage=0.8, multi_eval=False, use_log_transform=False):
    """
    Funci√≥n de evaluaci√≥n del modelo basada en backtesting.
    
    Parameters:
    -----------
    cv_periods : int
        N√∫mero de per√≠odos a usar para validaci√≥n
    initial : str
        Fecha inicial para la evaluaci√≥n (si es None, se usar√° un porcentaje de los datos)
    period : int
        Per√≠odo entre iteraciones de evaluaci√≥n
    horizon : int
        Horizonte de predicci√≥n para cada evaluaci√≥n
    max_iterations : int
        N√∫mero m√°ximo de iteraciones de validaci√≥n
    train_percentage : float
        Porcentaje de datos a usar para entrenamiento (entre 0.5 y 0.9)
    multi_eval : bool
        Si es True, realiza evaluaciones con m√∫ltiples puntos de corte
    use_log_transform : bool
        Si es True, aplica transformaci√≥n logar√≠tmica a los datos
    
    Returns:
    --------
    dict
        Diccionario con las m√©tricas de evaluaci√≥n calculadas a partir del modelo real
    """
    try:
        # Verificar que el modelo est√° entrenado
        if 'forecaster' not in st.session_state or st.session_state.forecaster is None:
            st.error("‚ö†Ô∏è Primero debe entrenar el modelo")
            return None
        
        # Para prop√≥sitos de diagn√≥stico, a√±adimos logs detallados
        st.info("üîç Iniciando evaluaci√≥n del modelo...")
        
        # Verificar que tengamos datos de entrenamiento
        df = None
        data_source = "desconocido"
        
        # Registrar el estado de los datos en este punto
        st.info("üîç Verificando fuentes de datos disponibles...")
        available_data = []
        
        # Comprobar todas las posibles fuentes de datos en orden de prioridad
        if hasattr(st.session_state.forecaster, 'df_prophet') and st.session_state.forecaster.df_prophet is not None:
            available_data.append(f"forecaster.df_prophet: {st.session_state.forecaster.df_prophet.shape}")
            df = st.session_state.forecaster.df_prophet
            data_source = "forecaster.df_prophet"
        
        if hasattr(st.session_state.forecaster, 'train_data') and st.session_state.forecaster.train_data is not None:
            available_data.append(f"forecaster.train_data: {st.session_state.forecaster.train_data.shape}")
            if df is None:
                df = st.session_state.forecaster.train_data
                data_source = "forecaster.train_data"
        
        if 'df_prophet_clean' in st.session_state and st.session_state.df_prophet_clean is not None:
            available_data.append(f"df_prophet_clean: {st.session_state.df_prophet_clean.shape}")
            if df is None:
                df = st.session_state.df_prophet_clean
                data_source = "df_prophet_clean"
        
        # Mostrar informaci√≥n de diagn√≥stico
        st.write("Fuentes de datos disponibles:")
        for source in available_data:
            st.write(f"- {source}")
        
        # Si no encontramos datos, no podemos continuar
        if df is None or len(df) == 0:
            st.error("‚ö†Ô∏è No hay datos disponibles para la evaluaci√≥n")
            
            # Diagn√≥stico detallado
            st.info("Informaci√≥n de diagn√≥stico:")
            st.info(f"- Variables disponibles en st.session_state: {[key for key in st.session_state.keys() if isinstance(st.session_state[key], pd.DataFrame)]}")
            
            raise ValueError("No hay datos disponibles para la evaluaci√≥n.")
        
        st.info(f"Usando datos de {data_source} para la evaluaci√≥n ({len(df)} registros).")
        
        # Verificar si tenemos suficientes datos para la evaluaci√≥n
        min_required = max(10, cv_periods)  # M√≠nimo absoluto: al menos el horizonte de evaluaci√≥n
        preferred_min = max(50, cv_periods * 3)  # M√≠nimo preferido: al menos 3 veces el horizonte
        
        if len(df) < preferred_min:
            st.warning(f"No hay suficientes datos para una evaluaci√≥n robusta (se tienen {len(df)} registros, se recomiendan al menos {preferred_min}).")
            
            if len(df) < min_required:
                st.error(f"Insuficientes datos para evaluaci√≥n. Se requieren al menos {min_required} registros.")
                raise ValueError(f"Insuficientes datos para evaluaci√≥n. Se necesitan al menos {min_required} registros, pero solo hay {len(df)}.")
            else:
                st.info("Realizando evaluaci√≥n con los datos disponibles, pero los resultados pueden no ser representativos.")
                
                # Ajustar par√°metros de evaluaci√≥n para conjuntos peque√±os de datos
                if cv_periods > len(df) // 3:
                    old_cv = cv_periods
                    cv_periods = max(5, len(df) // 3)
                    st.warning(f"Ajustando horizonte de evaluaci√≥n de {old_cv} a {cv_periods} d√≠as debido a la limitaci√≥n de datos.")
                
                if period is not None and period > len(df) // 5:
                    old_period = period
                    period = max(3, len(df) // 5)
                    st.warning(f"Ajustando periodo de evaluaci√≥n de {old_period} a {period} d√≠as debido a la limitaci√≥n de datos.")
                
                if max_iterations > len(df) // (cv_periods * 2):
                    old_iter = max_iterations
                    max_iterations = max(2, len(df) // (cv_periods * 2))
                    st.warning(f"Ajustando iteraciones de {old_iter} a {max_iterations} debido a la limitaci√≥n de datos.")
        
        # Si solicitamos m√∫ltiples evaluaciones
        if multi_eval:
            # Realizar evaluaciones con diferentes porcentajes de entrenamiento
            percentages = [0.6, 0.7, 0.8, 0.9]
            results = []
            
            for pct in percentages:
                st.subheader(f"Evaluaci√≥n con {int(pct*100)}% de datos para entrenamiento")
                # Llamar recursivamente a esta misma funci√≥n con diferentes porcentajes
                metrics = evaluate_model_wrapper(_self=_self, cv_periods=cv_periods, 
                                               train_percentage=pct, multi_eval=False)
                
                if metrics:
                    results.append({
                        'train_percentage': pct,
                        'metrics': metrics,
                        'cutoff_date': st.session_state.evaluation_details[0]['cutoff']
                    })
            
            # Mostrar tabla comparativa
            if results:
                st.subheader("Comparaci√≥n de Evaluaciones con Diferentes Puntos de Corte")
                
                # Crear dataframe para mostrar resultados
                comparison_df = pd.DataFrame({
                    'Porcentaje Entrenamiento': [f"{int(r['train_percentage']*100)}%" for r in results],
                    'Fecha de Corte': [r['cutoff_date'] for r in results],
                    'RMSE': [r['metrics']['rmse'] for r in results],
                    'MAE': [r['metrics']['mae'] for r in results],
                    'SMAPE': [f"{r['metrics']['smape']:.2f}%" for r in results],
                    'Cobertura': [f"{r['metrics']['coverage']:.2f}%" for r in results],
                    'Amplitud Promedio': [r['metrics'].get('interval_width_avg', 'N/A') for r in results]
                })
                
                st.table(comparison_df)
                
                # Recomendaciones basadas en los resultados
                st.subheader("An√°lisis de Resultados")
                
                # Analizar la variaci√≥n en el RMSE
                rmse_values = [r['metrics']['rmse'] for r in results]
                rmse_variation = max(rmse_values) - min(rmse_values)
                
                if rmse_variation > 0.5:
                    st.warning(f"Alta variaci√≥n en RMSE ({rmse_variation:.2f}): Los resultados son sensibles al punto de corte.")
                else:
                    st.success(f"Baja variaci√≥n en RMSE ({rmse_variation:.2f}): Los resultados son consistentes entre diferentes puntos de corte.")
                
                # Analizar la cobertura
                coverage_values = [r['metrics']['coverage'] for r in results]
                avg_coverage = sum(coverage_values) / len(coverage_values)
                
                if avg_coverage > 95:
                    st.warning(f"Cobertura promedio alta ({avg_coverage:.2f}%): Los intervalos de predicci√≥n podr√≠an ser demasiado conservadores.")
                else:
                    st.success(f"Cobertura promedio adecuada ({avg_coverage:.2f}%): Los intervalos de predicci√≥n parecen bien calibrados.")
                
                # Devolver el promedio de las m√©tricas
                return {
                    'rmse': sum(r['metrics']['rmse'] for r in results) / len(results),
                    'mae': sum(r['metrics']['mae'] for r in results) / len(results),
                    'smape': sum(r['metrics']['smape'] for r in results) / len(results),
                    'coverage': sum(r['metrics']['coverage'] for r in results) / len(results),
                    'iterations': len(results),
                    'horizon': cv_periods,
                    'multi_eval': True
                }
            
            return None
        
        # Para una √∫nica evaluaci√≥n, continuar con el proceso normal
        # Ajustar el train_percentage a un rango v√°lido
        train_percentage = max(0.5, min(0.95, train_percentage))
        
        # Determinar el punto de corte para entrenamiento/validaci√≥n basado en el porcentaje
        cutoff_idx = int(len(df) * train_percentage)
        
        # Asegurarse de que haya suficientes datos para validaci√≥n
        if len(df) - cutoff_idx < cv_periods:
            cv_periods = len(df) - cutoff_idx
            st.info(f"Ajustando per√≠odo de validaci√≥n a {cv_periods} d√≠as para mantener suficientes datos.")
        
        # Asegurarse de que haya suficientes datos para entrenamiento
        if cutoff_idx < 10:
            cutoff_idx = 10
            st.warning("Usando al menos 10 puntos para entrenamiento, puede no ser suficiente.")
        
        cutoff_date = df.iloc[cutoff_idx]['ds']
        
        # Dividir los datos en entrenamiento y prueba
        train_df = df[df['ds'] <= cutoff_date].copy()
        valid_df = df[df['ds'] > cutoff_date].copy()
        
        st.info(f"Realizando backtesting con punto de corte: {cutoff_date.strftime('%Y-%m-%d')}")
        st.info(f"Datos de entrenamiento: {len(train_df)} registros ({train_percentage*100:.1f}%)")
        st.info(f"Datos de validaci√≥n: {len(valid_df)} registros ({(1-train_percentage)*100:.1f}%)")
        
        # Crear y entrenar un nuevo modelo con los datos de entrenamiento
        # Usar los mismos par√°metros que el modelo original si es posible
        # Obtener el modelo de la sesi√≥n
        model = None
        
        # Verificar en las distintas ubicaciones donde podr√≠a estar el modelo
        if 'forecaster' in st.session_state:
            # Opci√≥n 1: El modelo est√° directamente en el atributo 'model'
            if hasattr(st.session_state.forecaster, 'model') and st.session_state.forecaster.model is not None:
                model = st.session_state.forecaster.model
                st.info("‚úÖ Modelo encontrado en forecaster.model")
            # Opci√≥n 2: El modelo est√° en 'prophet_model'
            elif hasattr(st.session_state.forecaster, 'prophet_model') and st.session_state.forecaster.prophet_model is not None:
                model = st.session_state.forecaster.prophet_model
                st.info("‚úÖ Modelo encontrado en forecaster.prophet_model")
            # Opci√≥n 3: La clase RansomwareProphetModel tiene su propio modelo interno
            elif hasattr(st.session_state.forecaster, 'ransomware_model') and hasattr(st.session_state.forecaster.ransomware_model, 'model'):
                model = st.session_state.forecaster.ransomware_model.model
                st.info("‚úÖ Modelo encontrado en forecaster.ransomware_model.model")
            # Intentar acceder al modelo directamente desde la sesi√≥n
            elif 'model' in st.session_state and st.session_state.model is not None:
                model = st.session_state.model
                st.info("‚úÖ Modelo encontrado en session_state.model")
            
            # Si no encontramos el modelo, usar valores predeterminados
            if model is not None:
                # Extraer par√°metros del modelo
                try:
                    params = {
                        'changepoint_prior_scale': model.changepoint_prior_scale,
                        'seasonality_prior_scale': model.seasonality_prior_scale,
                        'seasonality_mode': model.seasonality_mode,
                        'interval_width': model.interval_width
                    }
                    st.info("Usando par√°metros del modelo entrenado.")
                except AttributeError as e:
                    st.warning(f"Error al extraer par√°metros del modelo: {str(e)}")
                    # Usar valores predeterminados si no podemos extraer los par√°metros
                    params = {
                        'changepoint_prior_scale': 0.05,
                        'seasonality_prior_scale': 10.0,
                        'seasonality_mode': 'multiplicative',
                        'interval_width': 0.8  # Aumentar el ancho del intervalo para mejorar la cobertura
                    }
            else:
                # Si no se pueden extraer, usar valores predeterminados
                params = {
                    'changepoint_prior_scale': 0.05,
                    'seasonality_prior_scale': 10.0,
                    'seasonality_mode': 'multiplicative',
                    'interval_width': 0.8  # Aumentar el ancho del intervalo
                }
                st.warning("No se encontr√≥ un modelo entrenado en la sesi√≥n. Usando par√°metros predeterminados.")
            
            # Crear y entrenar el modelo de evaluaci√≥n
            from prophet import Prophet
            
            eval_model = Prophet(
                changepoint_prior_scale=params['changepoint_prior_scale'],
                seasonality_prior_scale=params['seasonality_prior_scale'],
                seasonality_mode=params['seasonality_mode'],
                interval_width=params['interval_width']
            )
            
            # Intentar a√±adir los mismos regresores si los tiene el modelo original
            if model is not None and hasattr(model, 'extra_regressors') and model.extra_regressors:
                for regressor_name, regressor_params in model.extra_regressors.items():
                    if regressor_name in train_df.columns:
                        try:
                            eval_model.add_regressor(regressor_name)
                        except Exception as e:
                            st.warning(f"No se pudo a√±adir el regresor {regressor_name}: {str(e)}")
            
            # Entrenar modelo con los datos de entrenamiento
            try:
                st.info(f"Entrenando modelo de evaluaci√≥n con {len(train_df)} filas de datos...")
                eval_model.fit(train_df)
            except Exception as e:
                st.error(f"Error al entrenar el modelo de evaluaci√≥n: {str(e)}")
                return None
            
            # SOLUCI√ìN PARA EL PROBLEMA DE FUSI√ìN DE DATOS: 
            # En lugar de hacer future_df y luego filtrar, vamos a crear directamente un dataframe
            # con exactamente las mismas fechas que el set de validaci√≥n
            try:
                st.info(f"Generando predicciones para {len(valid_df)} puntos de validaci√≥n...")
                
                # Crear un dataframe futuro usando exactamente las mismas fechas que valid_df
                future = pd.DataFrame({'ds': valid_df['ds'].values})
                
                # A√±adir los regresores al dataframe futuro si se usaron
                if model is not None and hasattr(model, 'extra_regressors') and model.extra_regressors:
                    for regressor_name in model.extra_regressors:
                        if regressor_name in df.columns:
                            try:
                                # Primero encontrar las fechas correspondientes en el df original
                                dates_map = dict(zip(df['ds'].dt.strftime('%Y-%m-%d'), df[regressor_name]))
                                # Luego mapear esos valores a las fechas en future
                                future[regressor_name] = future['ds'].dt.strftime('%Y-%m-%d').map(dates_map)
                            except Exception as e:
                                st.warning(f"No se pudo a√±adir el regresor {regressor_name} al dataframe futuro: {str(e)}")
                
                # Generar predicciones solo para las fechas de validaci√≥n
                forecast = eval_model.predict(future)
                
                # No es necesario filtrar porque ya tenemos solo las fechas que queremos
                forecast_valid = forecast
                
                st.info(f"Generadas {len(forecast_valid)} predicciones para el per√≠odo de validaci√≥n.")
            except Exception as e:
                st.error(f"Error al generar predicciones: {str(e)}")
                import traceback
                st.error(f"Detalles: {traceback.format_exc()}")
                return None
            
            # Asegurar que las fechas en ambos dataframes est√©n en el mismo formato
            try:
                # Asegurar que la columna 'ds' sea datetime en ambos dataframes
                valid_df['ds'] = pd.to_datetime(valid_df['ds'])
                forecast_valid['ds'] = pd.to_datetime(forecast_valid['ds'])
                
                # Mostrar diagn√≥stico de fechas
                st.info(f"Rango de fechas en validaci√≥n: {valid_df['ds'].min()} a {valid_df['ds'].max()}")
                st.info(f"Rango de fechas en predicci√≥n: {forecast_valid['ds'].min()} a {forecast_valid['ds'].max()}")
                
                # Fusionar datos para evaluaci√≥n
                test_with_preds = pd.merge(
                    valid_df, 
                    forecast_valid[['ds', 'yhat', 'yhat_lower', 'yhat_upper']], 
                    on='ds', 
                    how='inner'
                )
                
                # Verificar la fusi√≥n
                if len(test_with_preds) == 0:
                    st.error("La fusi√≥n de datos reales y predicciones result√≥ en 0 filas.")
                    
                    # Diagn√≥stico adicional
                    st.info("Diagn√≥stico de fechas:")
                    valid_dates = set(valid_df['ds'].dt.strftime('%Y-%m-%d'))
                    forecast_dates = set(forecast_valid['ds'].dt.strftime('%Y-%m-%d'))
                    
                    # Verificar si hay fechas comunes
                    common_dates = valid_dates.intersection(forecast_dates)
                    st.info(f"Fechas comunes: {len(common_dates)} de {len(valid_dates)} en validaci√≥n y {len(forecast_dates)} en predicci√≥n")
                    
                    if len(common_dates) == 0:
                        # Mostrar algunas fechas de cada conjunto para diagn√≥stico
                        st.info(f"Ejemplo de fechas en validaci√≥n: {list(valid_dates)[:5]}")
                        st.info(f"Ejemplo de fechas en predicci√≥n: {list(forecast_dates)[:5]}")
                        
                        # Intentar con una estrategia m√°s flexible basada en el d√≠a
                        st.info("Intentando estrategia alternativa de coincidencia de fechas...")
                        
                        # Crear columnas de fecha sin hora para ambos dataframes
                        valid_df['date_only'] = valid_df['ds'].dt.date
                        forecast_valid['date_only'] = forecast_valid['ds'].dt.date
                        
                        # Intentar fusionar por la fecha sin hora
                        test_with_preds = pd.merge(
                            valid_df, 
                            forecast_valid[['date_only', 'yhat', 'yhat_lower', 'yhat_upper']], 
                            on='date_only', 
                            how='inner'
                        )
                        
                        if len(test_with_preds) > 0:
                            st.success(f"¬°√âxito! Usando coincidencia de fecha sin hora, se encontraron {len(test_with_preds)} filas comunes.")
                        else:
                            st.error("No se pudo encontrar coincidencias ni siquiera usando solo la fecha sin hora.")
                            return None
                    else:
                        return None
                
                st.success(f"Fusi√≥n exitosa: {len(test_with_preds)} filas para calcular m√©tricas.")
                
            except Exception as e:
                st.error(f"Error al fusionar datos: {str(e)}")
                import traceback
                st.error(traceback.format_exc())
                return None
            
            # Verificar que tenemos todas las columnas necesarias
            required_cols = ['ds', 'y', 'yhat', 'yhat_lower', 'yhat_upper']
            missing_cols = [col for col in required_cols if col not in test_with_preds.columns]
            
            if missing_cols:
                st.error(f"Faltan columnas necesarias en los datos fusionados: {missing_cols}")
                st.write("Columnas disponibles:", list(test_with_preds.columns))
                return None
            
            # Verificar que no hay NaN en las columnas cr√≠ticas
            nan_counts = test_with_preds[required_cols].isna().sum()
            if nan_counts.sum() > 0:
                st.warning(f"Se detectaron valores NaN en los datos: {nan_counts}")
                # Eliminar filas con NaN en columnas cr√≠ticas
                test_with_preds = test_with_preds.dropna(subset=required_cols)
                st.info(f"Despu√©s de eliminar NaN, quedan {len(test_with_preds)} filas para m√©tricas.")
            
            if len(test_with_preds) == 0:
                st.error("No hay datos v√°lidos para calcular m√©tricas despu√©s de eliminar NaN.")
                return None
            
            # Calibrar intervalos de predicci√≥n adaptativamente
            try:
                # Calcular cobertura actual
                y_true = test_with_preds['y'].values
                y_pred = test_with_preds['yhat'].values
                interval_lower = test_with_preds['yhat_lower'].values
                interval_upper = test_with_preds['yhat_upper'].values
                
                current_coverage = ((y_true >= interval_lower) & (y_true <= interval_upper)).mean() * 100
                
                if current_coverage < 80.0 or current_coverage > 98.0:
                    st.info(f"Calibrando intervalos de predicci√≥n (cobertura actual: {current_coverage:.2f}%)...")
                    
                    # Aplicar factor de calibraci√≥n
                    target_coverage = 90.0  # 90% es un buen equilibrio
                    
                    # M√©todo simple para encontrar un factor que mejore la cobertura
                    if current_coverage < 80.0:
                        # Aumentar ancho de intervalos
                        scale_factor = 1.5
                    else:
                        # Reducir ancho de intervalos
                        scale_factor = 0.8
                        
                    # Aplicar calibraci√≥n
                    half_width = (interval_upper - interval_lower) / 2
                    center = (interval_upper + interval_lower) / 2
                    
                    # Recalcular l√≠mites
                    new_lower = center - half_width * scale_factor
                    new_upper = center + half_width * scale_factor
                    
                    # Actualizar dataframe
                    test_with_preds['yhat_lower'] = new_lower
                    test_with_preds['yhat_upper'] = new_upper
                    
                    # Actualizar valores para c√°lculo de m√©tricas
                    interval_lower = new_lower
                    interval_upper = new_upper
                    
                    # Calcular nueva cobertura
                    new_coverage = ((y_true >= interval_lower) & (y_true <= interval_upper)).mean() * 100
                    st.success(f"‚úÖ Intervalos calibrados: cobertura mejorada de {current_coverage:.2f}% a {new_coverage:.2f}%")
            except Exception as e:
                st.warning(f"No se pudieron calibrar los intervalos: {str(e)}")
            
            # Calcular m√©tricas
            try:
                from modeling.evaluation.metrics import calculate_metrics
                
                # Usar directamente la funci√≥n calculate_metrics para mayor precisi√≥n
                y_true = test_with_preds['y'].values
                y_pred = test_with_preds['yhat'].values
                interval_lower = test_with_preds['yhat_lower'].values
                interval_upper = test_with_preds['yhat_upper'].values
                
                # Calcular m√©tricas usando la funci√≥n centralizada
                metrics_result = calculate_metrics(y_true, y_pred, interval_lower, interval_upper)
                
                # Si por alguna raz√≥n fall√≥ el c√°lculo centralizado, usar el m√©todo de respaldo
                if metrics_result is None:
                    st.warning("Usando m√©todo alternativo para calcular m√©tricas...")
                    metrics_result = _calculate_forecast_metrics(test_with_preds)
                
                # Normalizar valores para mostrar correctamente como porcentajes
                if 'smape' in metrics_result and metrics_result['smape'] < 1.0:
                    metrics_result['smape'] = metrics_result['smape'] * 100

                if 'coverage' in metrics_result and metrics_result['coverage'] < 1.0:
                    metrics_result['coverage'] = metrics_result['coverage'] * 100
                
                # Verificar que las m√©tricas no son nulas
                for key, value in metrics_result.items():
                    if value is None or (isinstance(value, float) and (np.isnan(value) or np.isinf(value))):
                        st.warning(f"M√©trica {key} inv√°lida ({value}). Usando valor predeterminado.")
                        metrics_result[key] = 0.0
                
                # Crear diccionario final de m√©tricas
                metrics = {
                    'rmse': metrics_result.get('rmse', 0.0),
                    'mae': metrics_result.get('mae', 0.0),
                    'smape': metrics_result.get('smape', 0.0),
                    'coverage': metrics_result.get('coverage', 0.0),
                    'interval_width_avg': metrics_result.get('interval_width_avg', 0.0),
                    'interval_width_relative': metrics_result.get('interval_width_relative', 0.0),
                    'iterations': 1,
                    'horizon': cv_periods
                }
                
                # Mostrar resumen de m√©tricas
                st.info("üìä Resumen de m√©tricas calculadas:")
                st.info(f"RMSE: {metrics['rmse']:.4f}")
                st.info(f"MAE: {metrics['mae']:.4f}")
                st.info(f"SMAPE: {metrics['smape']:.2f}%")
                st.info(f"Cobertura de intervalos: {metrics['coverage']:.2f}%")
                if metrics['coverage'] < 80.0:
                    st.warning("‚ö†Ô∏è La cobertura del intervalo de predicci√≥n es baja. Considere aumentar el ancho del intervalo.")
                elif metrics['coverage'] > 98.0:
                    st.warning("‚ö†Ô∏è La cobertura del intervalo de predicci√≥n es muy alta. Considere reducir el ancho del intervalo para mejorar la precisi√≥n.")
            except Exception as e:
                st.error(f"Error al calcular m√©tricas: {str(e)}")
                st.session_state.model_trained = False
                
                # Mostrar informaci√≥n de depuraci√≥n
                if hasattr(st.session_state.forecaster, 'df_prophet') and st.session_state.forecaster.df_prophet is not None:
                    st.write(f"Columnas en df_prophet: {st.session_state.forecaster.df_prophet.columns.tolist()}")
                    
                return None
            
            # Crear detalles para visualizaci√≥n
            details = [{
                'rmse': metrics['rmse'],
                'mae': metrics['mae'],
                'smape': metrics['smape'],
                'coverage': metrics['coverage'],
                'cutoff': cutoff_date.strftime('%Y-%m-%d'),
                'num_points': len(test_with_preds),
                'interval_width_avg': metrics['interval_width_avg'],
                'interval_width_relative': metrics['interval_width_relative']
            }]
            
            # Guardar detalles para visualizaci√≥n
            st.session_state.evaluation_details = details
            
            # Guardar predicciones y valores reales para posible visualizaci√≥n
            if valid_df is not None and isinstance(valid_df, pd.DataFrame) and len(valid_df) > 0:
                st.session_state.valid_df = valid_df
            else:
                st.warning("No se pudieron guardar los datos de validaci√≥n para visualizaci√≥n.")
            
            if forecast_valid is not None and isinstance(forecast_valid, pd.DataFrame) and len(forecast_valid) > 0:
                st.session_state.forecast_valid = forecast_valid
            else:
                st.warning("No se pudieron guardar los datos de predicci√≥n para visualizaci√≥n.")
            
            # Mensaje de √©xito
            st.success("‚úÖ Evaluaci√≥n completada con √©xito usando datos reales.")
            
            return metrics
        
    except Exception as e:
        st.error(f"Error al evaluar el modelo: {str(e)}")
        st.session_state.model_trained = False
        
        # Mostrar informaci√≥n de depuraci√≥n
        if 'forecaster' in st.session_state and hasattr(st.session_state.forecaster, 'df_prophet') and st.session_state.forecaster.df_prophet is not None:
            st.write(f"Columnas en df_prophet: {st.session_state.forecaster.df_prophet.columns.tolist()}")
            
        return None