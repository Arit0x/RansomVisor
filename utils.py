import requests
import pandas as pd
import json
from pathlib import Path
import streamlit as st
from datetime import datetime

# â”€â”€â”€ CONFIG: DIRECTORIOS DE DATOS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_DIR = Path("data")
DATA_DIR.mkdir(exist_ok=True, parents=True)

# â”€â”€â”€ 1. SESIÃ“N HTTP REUTILIZABLE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def get_http_session() -> requests.Session:
    """Devuelve una sesiÃ³n persistente para todas las llamadas HTTP."""
    return requests.Session()

# â”€â”€â”€ 2. LÃ“GICA DE ACTUALIZACIÃ“N â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_update_flow():
    """Ejecuta los 3 pasos de actualizaciÃ³n y marca el flag en session_state."""
    total_steps = 3
    step = 0

    placeholder = st.container()
    progress_bar = placeholder.progress(0)

    # Paso 1
    old_ataques = load_snapshot("recentcyberattacks.json")
    ataques = actualizar_recentcyberattacks()
    delta_ataques = len(ataques) - len(old_ataques)
    step += 1; progress_bar.progress(int(step/total_steps*100))

    # Paso 2
    old_victims = load_snapshot("recentvictims.json")
    victimas = actualizar_recentvictims()
    delta_victims = len(victimas) - len(old_victims)
    step += 1; progress_bar.progress(int(step/total_steps*100))

    # Paso 3
    old_ano = load_snapshot("flattened_ransomware_year.json")
    victimas_ano = actualizar_snapshot_victimas_por_ano()
    delta_ano = len(victimas_ano) - len(old_ano)
    step += 1; progress_bar.progress(int(step/total_steps*100))

    placeholder.empty()

    st.session_state.update_result = {
        "ataques": ataques, "delta_ataques": delta_ataques,
        "victimas": victimas, "delta_victims": delta_victims,
        "victimas_ano": victimas_ano, "delta_ano": delta_ano
    }
    st.session_state.show_summary = True


def show_update_summary():
    """Muestra el resumen de la actualizaciÃ³n en la pÃ¡gina."""
    res = st.session_state.update_result
    st.success("âœ… ActualizaciÃ³n completada")
    c1, c2, c3 = st.columns(3)
    c1.metric("ðŸ“° Ataques recientes", len(res["ataques"]), delta=res["delta_ataques"])
    c2.metric("ðŸ“¢ VÃ­ctimas recientes", len(res["victimas"]), delta=res["delta_victims"])
    c3.metric("ðŸ—“ï¸ VÃ­ctimas por aÃ±o", len(res["victimas_ano"]), delta=res["delta_ano"])
    if st.button("Cerrar resumen", key="home_close_summary"):
        st.session_state.show_summary = False
        st.session_state.update_result = None

# â”€â”€â”€ 3. CONSULTA API CON CACHE â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=3600)
def consulta_api(endpoint: str, params: dict | None = None) -> dict:
    """
    Llama a la API de ransomware.live y devuelve JSON.
    Cachea el resultado durante 1 hora.
    """
    url = f"https://api.ransomware.live/v2/{endpoint}"
    resp = get_http_session().get(url, params=params, headers={"Accept": "application/json"})
    resp.raise_for_status()
    try:
        return resp.json() or {}
    except ValueError:
        return {}

# â”€â”€â”€ 4. FUNCIONES GENÃ‰RICAS DE SNAPSHOT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def load_snapshot(filename: str) -> list[dict]:
    """Carga JSON local de data/filename."""
    path = DATA_DIR / filename
    if path.exists():
        try:
            return json.loads(path.read_text(encoding="utf-8"))
        except json.JSONDecodeError:
            return []
    return []


def save_snapshot(data: list[dict], filename: str) -> None:
    """Guarda data en JSON 'data/filename'."""
    path = DATA_DIR / filename
    path.parent.mkdir(exist_ok=True, parents=True)
    path.write_text(json.dumps(data, ensure_ascii=False, indent=2, default=str), encoding="utf-8")


def fetch_incremental(
    endpoint: str,
    old_records: list[dict],
    date_field: str | None = 'date',
    params_extra: dict | None = None
) -> list[dict]:
    """
    Obtiene sÃ³lo los registros nuevos para endpoint segÃºn date_field,
    y desempaqueta payloads dict con clave 'data' en listas.
    """
    params = {}
    if date_field and old_records:
        df_old = pd.DataFrame(old_records)
        if date_field in df_old.columns:
            df_old[date_field] = pd.to_datetime(df_old[date_field], errors='coerce')
            last = df_old[date_field].max()
            if pd.notna(last):
                params['since'] = last.isoformat()
    if params_extra:
        params.update(params_extra)

    raw = consulta_api(endpoint, params) or []

    if isinstance(raw, dict):
        raw_list = raw.get('data') if isinstance(raw.get('data'), list) else []
    elif isinstance(raw, list):
        raw_list = raw
    else:
        raw_list = []

    if date_field and old_records and date_field in df_old.columns:
        df_new = pd.DataFrame(raw_list)
        if date_field in df_new.columns:
            df_new[date_field] = pd.to_datetime(df_new[date_field], errors='coerce')
            df_new = df_new[df_new[date_field] > last]
            raw_list = df_new.to_dict('records')

    return raw_list


def update_snapshot_generic(
    endpoint: str,
    filename: str,
    key_field: str = 'id',
    date_field: str | None = 'date',
    params_extra: dict | None = None
) -> list[dict]:
    """Actualiza snapshot: merge incremental + deduplicaciÃ³n."""
    old = load_snapshot(filename)
    inc = fetch_incremental(endpoint, old, date_field, params_extra)
    if inc:
        combined = old + inc
        df = pd.DataFrame(combined)
        if key_field and key_field in df.columns:
            df = df.drop_duplicates(subset=key_field, keep='last')
        records = df.to_dict('records')
        save_snapshot(records, filename)
        return records
    return old

# â”€â”€â”€ 5. WRAPPERS PARA VÃCTIMAS POR AÃ‘O â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def carga_snapshot_victimas_por_ano() -> list[dict]:
    return load_snapshot("flattened_ransomware_year.json")


def guarda_snapshot_victimas_por_ano(data: list[dict]) -> None:
    save_snapshot(data, "flattened_ransomware_year.json")


from datetime import datetime

def actualizar_snapshot_victimas_por_ano(start_year: int = 2021) -> list[dict]:
    """
    Si no hay datos locales, descarga todos los aÃ±os desde start_year hasta el actual;
    en ejecuciones posteriores, solo trae los aÃ±os nuevos (last_year+1 ... current_year),
    acumulando sin deduplicar dentro de cada aÃ±o.
    """
    # 1) Cargo lo viejo y determino el Ãºltimo aÃ±o procesado (o None si no hay)
    old = carga_snapshot_victimas_por_ano()
    aÃ±os_procesados = [r.get("year") for r in old if isinstance(r.get("year"), int)]
    last_year = max(aÃ±os_procesados) if aÃ±os_procesados else None

    # 2) AÃ±o actual y rango a consultar
    current_year = datetime.utcnow().year
    if last_year is None:
        aÃ±os_a_consultar = range(start_year, current_year + 1)
    else:
        aÃ±os_a_consultar = range(last_year + 1, current_year + 1)

    # 3) Arranco all_records con todo lo viejo
    all_records = list(old)

    # 4) Recorro cada aÃ±o nuevo y acumulo sin deduplicar
    for yr in aÃ±os_a_consultar:
        raw = consulta_api(f"victims/{yr}") or {}
        # desempaco payload si viene en dict
        lista = raw.get("victims") if isinstance(raw, dict) and isinstance(raw.get("victims"), list) else raw
        if not isinstance(lista, list):
            continue

        for v in lista:
            entry = v.copy() if isinstance(v, dict) else {"value": v}
            entry["year"] = yr
            all_records.append(entry)

    # 5) Serializo, guardo y devuelvo
    guarda_snapshot_victimas_por_ano(all_records)
    return all_records


# â”€â”€â”€ 7. WRAPPERS PARA ATAQUES RECIENTES EN PRENSA â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def carga_snapshot_recentcyberattacks() -> list[dict]:
    return load_snapshot("recentcyberattacks.json")


def actualizar_recentcyberattacks() -> list[dict]:
    return update_snapshot_generic(
        endpoint='recentcyberattacks',
        filename='recentcyberattacks.json',
        key_field='url',
        date_field='date'
    )

# â”€â”€â”€ 8. WRAPPERS PARA VÃCTIMAS RECIENTES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def carga_snapshot_recentvictims() -> list[dict]:
    return load_snapshot("recentvictims.json")


def actualizar_recentvictims() -> list[dict]:
    return update_snapshot_generic(
        endpoint='recentvictims',
        filename='recentvictims.json',
        key_field='victim',
        date_field='attackdate'
    )

# â”€â”€â”€ 9. NORMALIZACIÃ“N DE PAÃS, GRUPO Y SECTOR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ISO_TO_PAIS = {
    'AD': 'Andorra', 'AE': 'Emiratos Ãrabes Unidos', 'AF': 'AfganistÃ¡n', 'AG': 'Antigua y Barbuda',
    'AI': 'Anguila', 'AL': 'Albania', 'AM': 'Armenia', 'AO': 'Angola', 'AR': 'Argentina', 'AT': 'Austria',
    'AU': 'Australia', 'AW': 'Aruba', 'AZ': 'AzerbaiÃ¡n', 'BA': 'Bosnia y Herzegovina', 'BB': 'Barbados',
    'BD': 'BangladÃ©s', 'BF': 'Burkina Faso', 'BG': 'Bulgaria', 'BH': 'BarÃ©in', 'BI': 'Burundi', 'BM': 'Bermudas',
    'BN': 'BrunÃ©i', 'BO': 'Bolivia', 'BR': 'Brasil', 'BS': 'Bahamas', 'BW': 'Botsuana', 'BY': 'Bielorrusia',
    'BZ': 'Belice', 'CA': 'CanadÃ¡', 'CG': 'Congo', 'CH': 'Suiza', 'CI': 'Costa de Marfil', 'CL': 'Chile',
    'CM': 'CamerÃºn', 'CN': 'China', 'CO': 'Colombia', 'CP': 'Islas Cook', 'CR': 'Costa Rica', 'CU': 'Cuba',
    'CW': 'Curazao', 'CY': 'Chipre', 'CZ': 'RepÃºblica Checa', 'DE': 'Alemania', 'DJ': 'Yibuti', 'DK': 'Dinamarca',
    'DM': 'Dominica', 'DN': 'Dinamarca', 'DO': 'RepÃºblica Dominicana', 'DZ': 'Argelia', 'EC': 'Ecuador', 'EE': 'Estonia',
    'EG': 'Egipto', 'ER': 'Eritrea', 'ES': 'EspaÃ±a', 'ET': 'EtiopÃ­a', 'EU': 'UniÃ³n Europea', 'FI': 'Finlandia',
    'FJ': 'Fiyi', 'FO': 'Islas Feroe', 'FR': 'Francia', 'GA': 'GabÃ³n', 'GB': 'Reino Unido', 'GE': 'Georgia', 'GH': 'Ghana',
    'GI': 'Gibraltar', 'GL': 'Groenlandia', 'GM': 'Gambia', 'GR': 'Grecia', 'GT': 'Guatemala', 'GU': 'PaÃ­ses Bajos',
    'GY': 'Guyana', 'HK': 'Hong Kong', 'HN': 'Honduras', 'HR': 'Croacia', 'HT': 'HaitÃ­', 'HU': 'HungrÃ­a', 'ID': 'Indonesia',
    'IE': 'Irlanda', 'IL': 'Israel', 'IN': 'India', 'IQ': 'Irak', 'IR': 'IrÃ¡n', 'IS': 'Islandia', 'IT': 'Italia',
    'JA': 'JapÃ³n', 'JE': 'Jersey', 'JM': 'Jamaica', 'JO': 'Jordania', 'JP': 'JapÃ³n', 'KE': 'Kenia', 'KG': 'KirguistÃ¡n',
    'KH': 'Camboya', 'KI': 'Kiribati', 'KR': 'Corea del Sur', 'KW': 'Kuwait', 'KY': 'Islas CaimÃ¡n', 'KZ': 'KazajistÃ¡n',
    'LA': 'Laos', 'LB': 'LÃ­bano', 'LK': 'Sri Lanka', 'LS': 'Lesoto', 'LT': 'Lituania', 'LU': 'Luxemburgo', 'LV': 'Letonia',
    'LY': 'Libia', 'MA': 'Marruecos', 'MC': 'MÃ³naco', 'MD': 'Moldavia', 'ME': 'Montenegro', 'MG': 'Madagascar',
    'MK': 'Macedonia del Norte', 'ML': 'MalÃ­', 'MN': 'Mongolia', 'MO': 'Macao', 'MP': 'Islas Marianas del Norte',
    'MR': 'Mauritania', 'MU': 'Mauricio', 'MW': 'Malaui', 'MX': 'MÃ©xico', 'MY': 'Malasia', 'MZ': 'Mozambique', 'NA': 'Namibia',
    'NC': 'Nueva Caledonia', 'ND': 'NÃ­ger', 'NE': 'NÃ­ger', 'NG': 'Nigeria', 'NI': 'Nicaragua', 'NL': 'PaÃ­ses Bajos', 'NO': 'Noruega',
    'NP': 'Nepal', 'NZ': 'Nueva Zelanda', 'OM': 'OmÃ¡n', 'PA': 'PanamÃ¡', 'PE': 'PerÃº', 'PF': 'Polinesia Francesa',
    'PG': 'PapÃºa Nueva Guinea', 'PH': 'Filipinas', 'PK': 'PakistÃ¡n', 'PL': 'Polonia', 'PN': 'Islas Pitcairn', 'PO': 'Polonia',
    'PT': 'Portugal', 'PW': 'Palaos', 'PY': 'Paraguay', 'QA': 'Catar', 'QC': 'Quebec', 'RE': 'ReuniÃ³n', 'RO': 'RumanÃ­a',
    'RS': 'Serbia', 'RU': 'Rusia', 'RW': 'Ruanda', 'SA': 'Arabia Saudita', 'SB': 'Islas SalomÃ³n', 'SC': 'Seychelles', 'SD': 'SudÃ¡n',
    'SE': 'Suecia', 'SG': 'Singapur', 'SK': 'Eslovaquia', 'SL': 'Sierra Leona', 'SN': 'Senegal', 'SO': 'Somalia', 'SP': 'EspaÃ±a',
    'SR': 'Surinam', 'ST': 'Santo TomÃ© y PrÃ­ncipe', 'SV': 'El Salvador', 'SW': 'Suecia', 'SY': 'Siria', 'TC': 'Islas Turcas y Caicos',
    'TD': 'Chad', 'TH': 'Tailandia', 'TJ': 'TayikistÃ¡n', 'TL': 'Timor Oriental', 'TN': 'TÃºnez', 'TR': 'TurquÃ­a',
    'TT': 'Trinidad y Tobago', 'TU': 'TÃºnez', 'TV': 'Tuvalu', 'TZ': 'Tanzania', 'UA': 'Ucrania', 'UG': 'Uganda', 'UK': 'Reino Unido',
    'US': 'Estados Unidos', 'UY': 'Uruguay', 'UZ': 'UzbekistÃ¡n', 'VC': 'San Vicente y las Granadinas', 'VG': 'Islas VÃ­rgenes BritÃ¡nicas',
    'VI': 'Islas VÃ­rgenes EE.UU.', 'VN': 'Vietnam', 'WS': 'Samoa', 'ZA': 'SudÃ¡frica', 'ZM': 'Zambia', 'ZW': 'Zimbabue',
    'BE': 'BÃ©lgica', 'MM': 'Myanmar', 'MT': 'Malta', 'PR': 'Puerto Rico', 'TW': 'TaiwÃ¡n', 'VE': 'Venezuela',
    'ca': 'CanadÃ¡', 'cl': 'Chile', 'lk': 'Sri Lanka', 'tz': 'Tanzania', 'us': 'Estados Unidos'
}

GRUPO_SYNONYMS = {
    False: None, 'Lockbit':'LockBit', 'Lock Bit':'LockBit',
    'Revil':'REvil', 'Conti':'Conti', 'Maze':'Maze', 'Ryuk':'Ryuk'
}

ES_TO_SECTOR = {
    'Servicios empresariales':'Business Services', 'TecnologÃ­a':'Technology', 'Manufactura':'Manufacturing',
    'Salud':'Healthcare', 'Transporte y logÃ­stica':'Transportation/Logistics', 'Finanzas':'Financial',
    'Gobierno':'Government', 'Agricultura y alimentaciÃ³n':'Agriculture and Food Production', 'EnergÃ­a':'Energy',
    'EducaciÃ³n':'Education', 'HostelerÃ­a y turismo':'Hospitality and Tourism', 'Servicios al consumidor':'Consumer Services',
    'Sector pÃºblico':'Public Sector', 'Servicios financieros':'Financial Services','Instalaciones gubernamentales':'Government Facilities',
    'ConstrucciÃ³n':'Construction', 'TIC':'Information Technology', 'Salud pÃºblica':'Healthcare and Public Health',
    'Manufactura crÃ­tica':'Critical Manufacturing', 'Telecomunicaciones':'Telecommunication','Sistemas de transporte':'Transportation Systems',
    'Centros educativos':'Education Facilities','ComunicaciÃ³n':'Communication','Instalaciones comerciales':'Commercial Facilities',
    'Alimentos y agricultura':'Food and Agriculture','Servicios de emergencia':'Emergency Services','Comercio minorista':'Retail',
    'Mayorista y minorista':'Wholesale & Retail','IngenierÃ­a':'Engineering','QuÃ­mica':'Chemical','Publicidad, marketing y RRPP':'Advertising, Marketing & PR',
    'EnergÃ­a y suministros':'Energy & Utilities','Internet y telecomunicaciones':'Internet & Telecom Services','Base industrial de defensa':'Defense Industrial Base',
    'Transporte':'Transportation','Servicios legales':'Law Firms & Legal Services','Automotriz':'Automotive','ONGs':'Community, Social Services & Non-Profit Organisations',
    'Aeroespacial':'Aerospace','Alimentos y bebidas':'Food & Beverages','Otros':'Others','RadiodifusiÃ³n':'Broadcasting',
    'Inmobiliario':'Real Estate','Tratamiento de agua':'Water and Wastewater Systems','Nuclear':'Nuclear Reactors, Materials, and Waste',
    'FabricaciÃ³n TI':'IT Manufacturing','EnvÃ­os y logÃ­stica':'Shipping & Logistics','Legal':'Legal'
}

SECTOR_MAP_ESP = {
    'Information Technology': 'TecnologÃ­a de la informaciÃ³n',
    'Financial': 'Finanzas',
    'Business Services': 'Servicios empresariales',
    '': 'Desconocido',
    'Manufacturing': 'Manufactura',
    'Hospitality and Tourism': 'HostelerÃ­a y turismo',
    'Government': 'Gobierno',
    'Not Found': 'Desconocido',
    'Healthcare': 'Salud',
    'Engineering': 'IngenierÃ­a',
    'Government Facilities': 'Instalaciones gubernamentales',
    'Healthcare Services': 'Servicios de salud',
    'Wholesale & Retail': 'Comercio mayorista y minorista',
    'Law Firms & Legal Services': 'Servicios legales y bufetes de abogados',
    'Advertising, Marketing & Public Relations': 'Publicidad, marketing y relaciones pÃºblicas',
    'Aerospace': 'Aeroespacial',
    'Transportation/Logistics': 'Transporte y logÃ­stica',
    'Communication': 'ComunicaciÃ³n',
    'Energy': 'EnergÃ­a',
    'Telecommunication': 'Telecomunicaciones',
    'Agriculture': 'Agricultura',
    'Healthcare and Public Health': 'Salud pÃºblica y asistencia sanitaria',
    'Transportation Systems': 'Sistemas de transporte',
    'Technology': 'TecnologÃ­a',
    'Critical Manufacturing': 'Manufactura crÃ­tica',
    'Education Facilities': 'Instalaciones educativas',
    'Food and Agriculture': 'AlimentaciÃ³n y agricultura',
    'Commercial Facilities': 'Instalaciones comerciales',
    'Nuclear Reactors, Materials, and Waste': 'Reactores nucleares, materiales y residuos',
    'Chemical': 'Industria quÃ­mica',
    'Agriculture and Food Production': 'Agricultura y producciÃ³n alimentaria',
    'Others': 'Otros',
    'Internet & Telecommunication Services': 'Servicios de internet y telecomunicaciones',
    'Education': 'EducaciÃ³n',
    'Energy & Utilities': 'EnergÃ­a y servicios pÃºblicos',
    'Transportation': 'Transporte',
    'Automotive': 'AutomociÃ³n',
    'Community, Social Services & Non-Profit Organisations': 'Servicios sociales y organizaciones sin Ã¡nimo de lucro',
    'Broadcasting': 'RadiodifusiÃ³n',
    'Financial Services': 'Servicios financieros',
    'Defense Industrial Base': 'Industria de defensa',
    'Food & Beverages': 'AlimentaciÃ³n y bebidas',
    'Shipping & Logistics': 'EnvÃ­os y logÃ­stica',
    'IT Manufacturing': 'FabricaciÃ³n de TI',
    'Public Sector': 'Sector pÃºblico',
    'Construction': 'ConstrucciÃ³n',
    'Retail': 'Comercio minorista',
    'Consumer Services': 'Servicios al consumidor',
    'Real Estate': 'Bienes raÃ­ces',
    'Legal': 'Legal'
}
SECTOR_MAP_ESP.update(ES_TO_SECTOR)


def normalize_data(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    if 'country' in df.columns:
        pais_series = df['country']
    elif 'pais' in df.columns:
        pais_series = df['pais']
    else:
        pais_series = pd.Series([pd.NA] * len(df), index=df.index)

    df['pais'] = (
        pais_series
        .fillna('UNKNOWN')
        .astype(str)
        .str.strip()
        .replace(ISO_TO_PAIS)
        .fillna('Desconocido')
    )

    if 'claim_gang' in df.columns:
        grupo_series = df['claim_gang']
    elif 'grupo' in df.columns:
        grupo_series = df['grupo']
    else:
        grupo_series = pd.Series([pd.NA] * len(df), index=df.index)

    df['grupo'] = (
        grupo_series
        .fillna(False)
        .replace(GRUPO_SYNONYMS)
        .fillna('Desconocido')
        .astype(str)
        .str.strip()
        .str.title()
    )

    if 'sector' in df.columns:
        df['sector'] = df['sector'].map(SECTOR_MAP_ESP).fillna(df['sector'])

    return df

# â”€â”€â”€ 10. LOAD LOCAL SNAPSHOTS (SIN LLAMAR A LA API) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_data(ttl=3600)
def carga_datos_locales_alertas() -> pd.DataFrame:
    records = load_snapshot("alerts.json")
    if not records:
        return pd.DataFrame()
    df = pd.DataFrame(records)
    df = df.rename(columns={'timestamp':'fecha_alerta'})
    df['fecha_alerta'] = pd.to_datetime(df['fecha_alerta'], errors='coerce')
    return normalize_data(df)

@st.cache_data(ttl=3600)
def carga_datos_locales_recentcyberattacks() -> pd.DataFrame:
    records = load_snapshot("recentcyberattacks.json")
    if not records:
        return pd.DataFrame()
    df = pd.DataFrame(records)[[
        "claim_gang","country","date","victim","title","summary","url"
    ]]
    df = df.rename(columns={
        "claim_gang":"grupo","country":"pais","date":"fecha",
        "victim":"victima","title":"titulo","summary":"resumen"
    })
    df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
    return normalize_data(df)

@st.cache_data(ttl=3600)
def carga_datos_locales_recentvictims() -> pd.DataFrame:
    records = load_snapshot("recentvictims.json")
    if not records:
        return pd.DataFrame()
    df = pd.DataFrame(records)
    df = df.rename(columns={
        "attackdate":"fecha","group":"grupo","victim":"victima",
        "country":"pais","activity":"actividad","screenshot":"captura"
    })
    df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
    return normalize_data(df)

@st.cache_data(ttl=3600)
def carga_datos_victimas_por_ano() -> pd.DataFrame:
    records = carga_snapshot_victimas_por_ano()
    if not records:
        return pd.DataFrame()

    df = pd.DataFrame(records)
    cols = ['activity', 'attackdate', 'group', 'victim', 'country']
    df = df.loc[:, [c for c in cols if c in df.columns]]
    df = df.rename(columns={
        'activity':    'sector',
        'attackdate':  'fecha',
        'group':       'grupo',
        'victim':      'victima',
        'country':     'pais'
    })
    if 'fecha' in df.columns:
        df['fecha'] = pd.to_datetime(df['fecha'], errors='coerce')
    df['pais'] = (
        df['pais']
        .astype(str)
        .str.strip()
        .replace('', pd.NA)
        .fillna('Desconocido')
    )
    df['sector'] = (
        df['sector']
        .astype(str)
        .str.strip()
        .replace(r'(?i)^(?:|not\s*found)$', pd.NA, regex=True)
        .fillna('Desconocido')
    )
    return normalize_data(df)

# â”€â”€â”€ XX. CSS LEGADO â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_css(path: str = 'assets/style.css') -> None:
    file = Path(path)
    if file.exists():
        st.markdown(f"<style>{file.read_text()}</style>", unsafe_allow_html=True)
